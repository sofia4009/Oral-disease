{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sofia4009/Oral-disease/blob/main/Train_Test_KaggleDS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "012e2c86",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "012e2c86",
        "outputId": "ee1f4b28-c83a-4676-9512-4be1947cf4cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Author: Sofia\\nDate: March 26\\nSubject: Oral Diseases Classification\\nDescription:\\nClassification of a dataset named ds_A from kaggle:  https://www.kaggle.com/datasets/salmansajid05/oral-diseases\\n  - without data augmentation\\n  - normalise all image pixel values to the range [0, 1]\\n  - resize all images to dimensions 112x112x3 for speeding up the training\\n  - use stratified k-fold cross validation (with k = 5) to split ds_A\\n  - use the following deep neural network models for training, testing and comparing their performance:\\n    - ResNet18, ResNet50, ConvNeXt, EfficientNetB0, Transformers (i.e., ViT)\\n  - use categorical cross entropy as the loss function and f1_score as evaluation metric\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\"\"\"Author: Sofia\n",
        "Date: March 26\n",
        "Subject: Oral Diseases Classification\n",
        "Description:\n",
        "Classification of a dataset named ds_A from kaggle:  https://www.kaggle.com/datasets/salmansajid05/oral-diseases\n",
        "  - without data augmentation\n",
        "  - normalise all image pixel values to the range [0, 1]\n",
        "  - resize all images to dimensions 112x112x3 for speeding up the training\n",
        "  - use stratified k-fold cross validation (with k = 5) to split ds_A\n",
        "  - use the following deep neural network models for training, testing and comparing their performance:\n",
        "    - ResNet18, ResNet50, ConvNeXt, EfficientNetB0, Transformers (i.e., ViT)\n",
        "  - use categorical cross entropy as the loss function and f1_score as evaluation metric\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation and adding packages"
      ],
      "metadata": {
        "id": "5W8Jq6qL1MiA"
      },
      "id": "5W8Jq6qL1MiA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae11c53c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae11c53c",
        "outputId": "92aee35e-d287-46cc-81ea-c9d317d032c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.4)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.6.14)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.31.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.7)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ],
      "source": [
        "!pip install opendatasets\n",
        "\n",
        "# Install kaggle API client\n",
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21a162e2",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "21a162e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dc2ed52-4c92-4c5a-a577-bec6db180c14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import zipfile\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a16a4990",
      "metadata": {
        "id": "a16a4990"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from openpyxl import load_workbook\n",
        "from openpyxl.drawing.image import Image as xlImage\n",
        "from openpyxl import Workbook"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initializations"
      ],
      "metadata": {
        "id": "oINNvcZU1J5i"
      },
      "id": "oINNvcZU1J5i"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ca4c0d4",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "5ca4c0d4"
      },
      "outputs": [],
      "source": [
        "# Normalizing them to [0,1], Resizing to 112,112, 3\n",
        "def normalize_and_resize_image(image, target_size):\n",
        "\n",
        "    # Resize image into 112*112*3\n",
        "    image = image.resize(target_size)\n",
        "\n",
        "    # Normalize pixel values to the range [0, 1]\n",
        "    image = np.array(image)\n",
        "    image = image / 255.0\n",
        "\n",
        "    # Convert the normalized numpy array back to PIL image\n",
        "    image = Image.fromarray((image * 255).astype(np.uint8))\n",
        "\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = (112,112)\n",
        "\n",
        "# Specify the root directory where your images are located\n",
        "main_DS_directory = '/content/oral-diseases'\n",
        "\n",
        "# Specify the output directory to save the processed images\n",
        "Preprocessed_DS_directory = '/content/decreased_oral_diseases'\n",
        "\n",
        "# Specify the output directory to save the excel file\n",
        "results_directory = '/content/drive/My Drive/QM/results.xlsx'\n",
        "Plot_directory = '/content/drive/My Drive/QM/plots.xlsx'"
      ],
      "metadata": {
        "id": "rSb5Ka6oztRc"
      },
      "id": "rSb5Ka6oztRc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload() #To prompt to upload the kaggle.json\n",
        "\n",
        "# kaggle API client expects the file to be in ~/.kaggle\n",
        "# so move it there\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# we need to set permissions\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "# check your directory before downloading the datasets\n",
        "!pwd\n",
        "\n",
        "# download the required dataset from kaggle\n",
        "!kaggle datasets download -d salmansajid05/oral-diseases\n",
        "\n",
        "with zipfile.ZipFile('oral-diseases.zip', \"r\") as z:\n",
        "    z.extractall(main_DS_directory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b1ypqCgzdjD",
        "outputId": "ac5535a0-10a7-4768-dfd9-9075b71047b5"
      },
      "id": "0b1ypqCgzdjD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-559969e0-dcce-4256-9590-71e66fb1b698\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-559969e0-dcce-4256-9590-71e66fb1b698\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "/content\n",
            "Dataset URL: https://www.kaggle.com/datasets/salmansajid05/oral-diseases\n",
            "License(s): unknown\n",
            "Downloading oral-diseases.zip to /content\n",
            " 99% 233M/235M [00:08<00:00, 34.0MB/s]\n",
            "100% 235M/235M [00:08<00:00, 27.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04395f74",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "04395f74"
      },
      "outputs": [],
      "source": [
        "# Normalizing them to [0,1], Resizing to 112,112, 3\n",
        "def normalize_and_resize_image(image, target_size):\n",
        "\n",
        "    # Resize image into 112*112*3\n",
        "    image = image.resize(target_size)\n",
        "\n",
        "    # Normalize pixel values to the range [0, 1]\n",
        "    image = np.array(image)\n",
        "    image = image / 255.0\n",
        "\n",
        "    # Convert the normalized numpy array back to PIL image\n",
        "    image = Image.fromarray((image * 255).astype(np.uint8))\n",
        "\n",
        "    return image\n",
        "\n",
        "# Saving the normalized images into a new directory in Google colab with the same subdirectories and structure\n",
        "def process_images_in_directory(directory, Preprocessed_DS_directory):\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            # Check if the file has an image extension\n",
        "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
        "                # Construct the full path to the input image file\n",
        "                image_path = os.path.join(root, file)\n",
        "                if 'augmented' not in image_path and 'Caries_Gingivitus_ToothDiscoloration_Ulcer-yolo_annotated-Dataset' not in image_path:\n",
        "                  # Open the image using PIL\n",
        "                  image = Image.open(image_path)\n",
        "\n",
        "                  # Ensure image is in RGB mode\n",
        "                  image = image.convert(\"RGB\")\n",
        "\n",
        "                  # Normalize and Resize the image\n",
        "                  #print(image_path)\n",
        "                  processed_image = normalize_and_resize_image(image, image_size)\n",
        "\n",
        "                  # Construct the full path to the output directory\n",
        "                  output_subdirectory = os.path.relpath(root, directory)\n",
        "                  output_path = os.path.join(Preprocessed_DS_directory, output_subdirectory)\n",
        "                  os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "                  # Save the processed image\n",
        "                  filename = os.path.join(output_path, file)\n",
        "                  processed_image.save(filename, format='JPEG')  # Change 'JPEG' to the desired format\n",
        "                  #print(filename)\n",
        "                  #if filename.find('augmented') == -1 or filename.find('Caries_Gingivitus_ToothDiscoloration_Ulcer-yolo_annotated-Dataset') == -1:\n",
        "                  #np.save(filename, image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1329991",
      "metadata": {
        "id": "f1329991"
      },
      "outputs": [],
      "source": [
        "# Call the function to process images in the directory\n",
        "process_images_in_directory(main_DS_directory, Preprocessed_DS_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75204e41",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75204e41",
        "outputId": "0bd286d9-d2c7-4090-dbdd-f31fcd39935d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Original Images: 15373\n",
            "Number of Preprocessed Images: 5563\n"
          ]
        }
      ],
      "source": [
        "file_count = sum(len(files) for _, _, files in os.walk(main_DS_directory))\n",
        "print(f\"Number of Original Images: {file_count}\")\n",
        "\n",
        "file_count = sum(len(files) for _, _, files in os.walk(Preprocessed_DS_directory))\n",
        "print(f\"Number of Preprocessed Images: {file_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a83fdad2",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "a83fdad2"
      },
      "source": [
        "# Initializations for training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6258ca3",
      "metadata": {
        "id": "a6258ca3"
      },
      "source": [
        "Define transformations by Composing several transforms together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e428d832",
      "metadata": {
        "id": "e428d832"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    #Convert a PIL Image or ndarray to tensor\n",
        "    transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bf05d82",
      "metadata": {
        "id": "1bf05d82"
      },
      "outputs": [],
      "source": [
        "# Use ImageFolder to load your dataset\n",
        "dataset = torchvision.datasets.ImageFolder(root = Preprocessed_DS_directory, transform=transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8c6588b",
      "metadata": {
        "id": "e8c6588b"
      },
      "source": [
        "Preprocessed_DS_directory, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee551624",
      "metadata": {
        "id": "ee551624"
      },
      "outputs": [],
      "source": [
        "# Define number of classes and list of labels in the dataset\n",
        "num_classes = len(dataset.classes)\n",
        "classes = dataset.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bfe588d",
      "metadata": {
        "id": "1bfe588d"
      },
      "outputs": [],
      "source": [
        "# Define k-fold for cross-validation\n",
        "k_folds = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fe58e8a",
      "metadata": {
        "id": "7fe58e8a"
      },
      "outputs": [],
      "source": [
        "# Seed (random_state) is set to initialize the random number generator while splitting the DataSet into k folds\n",
        "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9235a70",
      "metadata": {
        "id": "f9235a70"
      },
      "outputs": [],
      "source": [
        "# Define hyperparameters to search over\n",
        "learning_rates = [0.001, 0.0001]\n",
        "batch_sizes = [32, 64, 128]\n",
        "optimizers = ['Adam', 'SGD', 'RMSprop']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bc625da",
      "metadata": {
        "id": "3bc625da"
      },
      "outputs": [],
      "source": [
        "epochs = 35"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68498e68",
      "metadata": {
        "id": "68498e68"
      },
      "outputs": [],
      "source": [
        "best_model = None\n",
        "best_f1 = 0.0\n",
        "best_hyperparameters = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "245eeb69",
      "metadata": {
        "id": "245eeb69"
      },
      "outputs": [],
      "source": [
        "#print(classes)\n",
        "class_counts = {}\n",
        "for class_name in os.listdir(Preprocessed_DS_directory):\n",
        "    # Construct the full path to the class directory\n",
        "    class_directory = os.path.join(Preprocessed_DS_directory, class_name)\n",
        "\n",
        "    # Check if the path is a directory\n",
        "    if os.path.isdir(class_directory):\n",
        "        # Count the number of files in the class directory\n",
        "        num_files = len(os.listdir(class_directory))\n",
        "\n",
        "        # Store the count in the class_counts dictionary\n",
        "        class_counts[class_name] = num_files"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ConvNexT"
      ],
      "metadata": {
        "id": "Q5Nq5ZO1iGYz"
      },
      "id": "Q5Nq5ZO1iGYz"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"# ConvNeXt\"\"\"\n",
        "\n",
        "# An empty list for storing the results\n",
        "results = []\n",
        "f1_vals = [0] * k_folds\n",
        "results.append({'Model': 'ConvNeXt'})\n",
        "\n",
        "# Initialize lists to store training and validation losses and accuracies\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "num_epochs = epochs\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for batch_size in batch_sizes:\n",
        "      for optimizer_name in optimizers:\n",
        "        print(\"Training with optimizer: \" + optimizer_name + \", learning rate: \" + str(lr) + \", batch size: \" + str(batch_size))\n",
        "\n",
        "#        print(f\"Training with optimizer: {optimizer_name}, learning rate: {lr}, batch size: {batch_size}\")\n",
        "        for fold, (train_idx, val_idx) in enumerate(skf.split(dataset.imgs, dataset.targets)):\n",
        "            train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
        "            val_sampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
        "\n",
        "            #train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "            #val_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=val_sampler)\n",
        "\n",
        "            train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, pin_memory=True)\n",
        "            val_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=val_sampler, pin_memory=True)\n",
        "\n",
        "            best_f1 = 0\n",
        "\n",
        "            # Define the neural network\n",
        "\n",
        "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "            model = torchvision.models.convnext_small(input_shape=image_size, num_classes=num_classes).to(device)\n",
        "\n",
        "            #model = torchvision.models.convnext_small(input_shape=image_size, num_classes=num_classes)\n",
        "\n",
        "            # Define loss function\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            # Define optimizer\n",
        "            if optimizer_name == 'Adam':\n",
        "                optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "            elif optimizer_name == 'SGD':\n",
        "                optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "            elif optimizer_name == 'RMSprop':\n",
        "                optimizer = optim.RMSprop(model.parameters(), lr=lr)\n",
        "\n",
        "            # Train and evaluate\n",
        "            for epoch in range(num_epochs):\n",
        "                # Training loop\n",
        "                model.train()\n",
        "                running_loss = 0.0\n",
        "                correct = 0\n",
        "                total = 0\n",
        "                for inputs, labels in train_loader:\n",
        "\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    running_loss += loss.item()\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (preds == labels).sum().item()\n",
        "                epoch_train_loss = running_loss / len(train_loader)\n",
        "                epoch_train_accuracy = correct / total\n",
        "                train_losses.append(epoch_train_loss)\n",
        "                train_accuracies.append(epoch_train_accuracy)\n",
        "\n",
        "                # Validation loop\n",
        "                model.eval()\n",
        "                all_preds = []\n",
        "                all_labels = []\n",
        "                running_loss = 0.0\n",
        "                correct = 0\n",
        "                total = 0\n",
        "                with torch.no_grad():\n",
        "                   for inputs, labels in val_loader:\n",
        "\n",
        "                      inputs, labels = inputs.to(device), labels.to(device)\n",
        "                      outputs = model(inputs)\n",
        "                      loss = criterion(outputs, labels)\n",
        "                      running_loss += loss.item()\n",
        "                      _, preds = torch.max(outputs, 1)\n",
        "                      total += labels.size(0)\n",
        "                      correct += (preds == labels).sum().item()\n",
        "                      all_preds.extend(preds.cpu().numpy())\n",
        "                      all_labels.extend(labels.cpu().numpy())\n",
        "                epoch_val_loss = running_loss / len(val_loader)\n",
        "                epoch_val_accuracy = correct / total\n",
        "                val_losses.append(epoch_val_loss)\n",
        "                val_accuracies.append(epoch_val_accuracy)\n",
        "\n",
        "                # Calculate F1 score\n",
        "                f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "                #print(f\"Fold {fold+1}, Epoch {epoch+1}, F1 Score: {f1}\")\n",
        "                print(\"Fold \" + str(fold+1) + \", Epoch \" + str(epoch+1) + \", F1 Score: \" + str(f1))\n",
        "                # Update best F1 score and model\n",
        "                if f1 > best_f1:\n",
        "                  best_f1 = f1\n",
        "\n",
        "            f1_vals[fold] = best_f1\n",
        "            results.append({\n",
        "                    'model': 'ConvNeXt_small',\n",
        "                    'Optimizer': optimizer_name,\n",
        "                    'batch_size': batch_size,\n",
        "                    'learning_rate': lr,\n",
        "                    'Fold': fold+1,\n",
        "                    'F1 Score': best_f1\n",
        "                    })\n",
        "        results.append({\n",
        "                  'min f1': min(f1_vals),\n",
        "                  'max f1': max(f1_vals),\n",
        "                  'average f1': sum(f1_vals)/len(f1_vals)\n",
        "                  })\n",
        "\n",
        "        # Save the results as a DataFrame to be saved in an Excel file\n",
        "        df = pd.DataFrame(results)\n",
        "\n",
        "        # Load an existing Excel file\n",
        "        if os.path.isfile(results_directory):\n",
        "            existing_file = pd.read_excel(results_directory)\n",
        "            # Append the new DataFrame to the existing file\n",
        "            df = pd.concat([existing_file, df])\n",
        "\n",
        "        # Write the DataFrame to the excel file in the directory\n",
        "        df.to_excel(results_directory, index=False)\n",
        "# -------------- End of Save the results in a excel file ----------------\n",
        "\n"
      ],
      "metadata": {
        "id": "72G0rSvfiKEj"
      },
      "id": "72G0rSvfiKEj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- Save the results in a excel file ---------------------\n",
        "# Save the results as a DataFrame to be saved in an Excel file\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "# Load an existing Excel file\n",
        "if os.path.isfile(results_directory):\n",
        "  existing_file = pd.read_excel(results_directory)\n",
        "  # Append the new DataFrame to the existing file\n",
        "  df = pd.concat([existing_file, df])\n",
        "\n",
        "# Write the DataFrame to the excel file in the directory\n",
        "df.to_excel(results_directory, index=False)\n",
        "# -------------- End of Save the results in a excel file ----------------\n",
        "\n",
        "# -------------------- Plot the error/epoch plot ------------------------\n",
        "\n",
        "# Define the filename for the Excel file\n",
        "excel_filename = Plot_directory\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(os.path.dirname(excel_filename), exist_ok=True)\n",
        "\n",
        "# Check if the Excel file exists\n",
        "if os.path.exists(excel_filename):\n",
        "    # Load existing Excel file\n",
        "    wb = load_workbook(excel_filename)\n",
        "    ws = wb.active\n",
        "else:\n",
        "    # Create a new Excel workbook\n",
        "    wb = Workbook()\n",
        "    ws = wb.active"
      ],
      "metadata": {
        "id": "9pWD6stRsohH"
      },
      "id": "9pWD6stRsohH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer: ViT"
      ],
      "metadata": {
        "id": "RRa1q6mPaad7"
      },
      "id": "RRa1q6mPaad7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcc6b397",
      "metadata": {
        "id": "dcc6b397"
      },
      "outputs": [],
      "source": [
        "# Define transformations with a smaller image size\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Reduce image size\n",
        "    transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64411300",
      "metadata": {
        "id": "64411300"
      },
      "outputs": [],
      "source": [
        "# Use ImageFolder to load your dataset\n",
        "dataset = torchvision.datasets.ImageFolder(root=Preprocessed_DS_directory, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15e197fb",
      "metadata": {
        "id": "15e197fb"
      },
      "outputs": [],
      "source": [
        "# Initialize lists to store training and validation losses and accuracies\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23e3d2b7",
      "metadata": {
        "id": "23e3d2b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225,
          "referenced_widgets": [
            "e15c5b77190d4d58b20721ba2b560ed5",
            "7493f6137bae478ca3d498a7499c6faa",
            "7cdfb86992574375b12c4f855fa22b47",
            "c6b4bf9cf79f4e8c960038894914e8f6",
            "d6f8b7af62934a3dbadae60ce6d4717b",
            "99df0033143f4abf840bf362cd83b220",
            "5eb2a5628cad4f159587ee8bfea63ecb",
            "b9dadfbdf83a432d8f16b8761b3cd377",
            "0cda12e1b4274fa5881c22c6ae8b599c",
            "32c32871fe94446a9a9ffb77dcc407ef",
            "3e24f8f2ac79438fbd9b9c84736db73b"
          ]
        },
        "outputId": "d672ca97-402e-48ae-a2bf-380ee3209eba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with optimizer: Adam, learning rate: 0.001, batch size: 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e15c5b77190d4d58b20721ba2b560ed5"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "\"\"\"#Transformer: ViT\"\"\"\n",
        "\n",
        "from transformers import ViTModel, ViTConfig\n",
        "\n",
        "# Define transformations by Composing several transforms together\n",
        "# and change th image_size to (224*224) to be compatible with ViT\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(224*224),\n",
        "    #Convert a PIL Image or ndarray to tensor\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "\n",
        "# Use ImageFolder to load your dataset\n",
        "dataset = torchvision.datasets.ImageFolder(root = Preprocessed_DS_directory, transform=transform)\n",
        "\n",
        "# Define number of classes and list of labels in the dataset\n",
        "num_classes = len(dataset.classes)\n",
        "classes = dataset.classes\n",
        "\n",
        "# An empty list for storing the results\n",
        "results = []\n",
        "f1_vals = [0] * k_folds\n",
        "results.append({'Model': 'Transformr: ViT'})\n",
        "\n",
        "# Initialize lists to store training and validation losses and accuracies\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "num_epochs = epochs\n",
        "\n",
        "for batch_size in batch_sizes:\n",
        "    for lr in learning_rates:\n",
        "      for optimizer_name in optimizers:\n",
        "        #print(f\"Training with optimizer: {optimizer_name}, learning rate: {lr}, batch size: {batch_size}\")\n",
        "        print(\"Training with optimizer: \" + optimizer_name + \", learning rate: \" + str(lr) + \", batch size: \" + str(batch_size))\n",
        "        for fold, (train_idx, val_idx) in enumerate(skf.split(dataset.imgs, dataset.targets)):\n",
        "            train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
        "            val_sampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
        "\n",
        "            train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "            val_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=val_sampler)\n",
        "\n",
        "            best_f1 = 0\n",
        "\n",
        "            # Define the device (GPU if available, otherwise CPU)\n",
        "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "            # Define the neural network\n",
        "            config = ViTConfig.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "            model = ViTModel(config).to(device)  # Move the model to GPU\n",
        "\n",
        "            #model = ViTModel(config)\n",
        "\n",
        "            # Define loss function\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            # Define optimizer\n",
        "            if optimizer_name == 'Adam':\n",
        "                optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "            elif optimizer_name == 'SGD':\n",
        "                optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "            elif optimizer_name == 'RMSprop':\n",
        "                optimizer = optim.RMSprop(model.parameters(), lr=lr)\n",
        "\n",
        "            # Train and evaluate\n",
        "            for epoch in range(num_epochs):\n",
        "                # Training loop\n",
        "                model.train()\n",
        "                running_loss = 0.0\n",
        "                correct = 0\n",
        "                total = 0\n",
        "                for inputs, labels in train_loader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device) # Move inputs and labels to GPU\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    running_loss += loss.item()\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (preds == labels).sum().item()\n",
        "                epoch_train_loss = running_loss / len(train_loader)\n",
        "                epoch_train_accuracy = correct / total\n",
        "                train_losses.append(epoch_train_loss)\n",
        "                train_accuracies.append(epoch_train_accuracy)\n",
        "\n",
        "                # Validation loop\n",
        "                model.eval()\n",
        "                all_preds = []\n",
        "                all_labels = []\n",
        "                running_loss = 0.0\n",
        "                correct = 0\n",
        "                total = 0\n",
        "                with torch.no_grad():\n",
        "                  for inputs, labels in val_loader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)  # Move inputs and labels to GPU\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    running_loss += loss.item()\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (preds == labels).sum().item()\n",
        "                    all_preds.extend(preds.cpu().numpy())\n",
        "                    all_labels.extend(labels.cpu().numpy())\n",
        "                epoch_val_loss = running_loss / len(val_loader)\n",
        "                epoch_val_accuracy = correct / total\n",
        "                val_losses.append(epoch_val_loss)\n",
        "                val_accuracies.append(epoch_val_accuracy)\n",
        "\n",
        "                # Calculate F1 score\n",
        "                f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "                #print(f\"Fold {fold+1}, Epoch {epoch+1}, F1 Score: {f1}\")\n",
        "                print(\"Fold \" + str(fold+1) + \", Epoch \" + str(epoch+1) + \", F1 Score: \" + str(f1))\n",
        "                # Update best F1 score and model\n",
        "                if f1 > best_f1:\n",
        "                  best_f1 = f1\n",
        "\n",
        "            f1_vals[fold] = best_f1\n",
        "            results.append({\n",
        "                    'Optimizer': optimizer_name,\n",
        "                    'batch_size': batch_size,\n",
        "                    'learning_rate': lr,\n",
        "                    'Fold': fold+1,\n",
        "                    'F1 Score': best_f1\n",
        "              })\n",
        "        results.append({\n",
        "                  'min f1': min(f1_vals),\n",
        "                  'max f1': max(f1_vals),\n",
        "                  'average f1': sum(f1_vals)/len(f1_vals)\n",
        "                  })\n",
        "\n",
        "        # Define the filename for the Excel file\n",
        "        excel_filename = Plot_directory\n",
        "\n",
        "        # Create the directory if it doesn't exist\n",
        "        os.makedirs(os.path.dirname(excel_filename), exist_ok=True)\n",
        "\n",
        "        # Check if the Excel file exists\n",
        "        if os.path.exists(excel_filename):\n",
        "            # Load existing Excel file\n",
        "            wb = load_workbook(excel_filename)\n",
        "            ws = wb.active\n",
        "        else:\n",
        "            # Create a new Excel workbook\n",
        "            wb = Workbook()\n",
        "            ws = wb.active\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "        # Save the results as a DataFrame to be saved in an Excel file\n",
        "        df = pd.DataFrame(results)\n",
        "\n",
        "        # Load an existing Excel file\n",
        "        if os.path.isfile(results_directory):\n",
        "            existing_file = pd.read_excel(results_directory)\n",
        "            # Append the new DataFrame to the existing file\n",
        "            df = pd.concat([existing_file, df])\n",
        "\n",
        "        # Write the DataFrame to the excel file in the directory\n",
        "        df.to_excel(results_directory, index=False)\n",
        "# -------------------- Plot the error/epoch plot ------------------------\n",
        "\n",
        "# Define the filename for the Excel file\n",
        "excel_filename = Plot_directory\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(os.path.dirname(excel_filename), exist_ok=True)\n",
        "\n",
        "# Check if the Excel file exists\n",
        "if os.path.exists(excel_filename):\n",
        "    # Load existing Excel file\n",
        "    wb = load_workbook(excel_filename)\n",
        "    ws = wb.active\n",
        "else:\n",
        "    # Create a new Excel workbook\n",
        "    wb = Workbook()\n",
        "    ws = wb.active"
      ],
      "metadata": {
        "id": "w4bamGOdsces"
      },
      "id": "w4bamGOdsces",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet18"
      ],
      "metadata": {
        "id": "6j3APNj0jhvY"
      },
      "id": "6j3APNj0jhvY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3453b903",
      "metadata": {
        "id": "3453b903",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba5106f1-463f-49f8-b4bb-c6834a0b6461"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with optimizer: Adam, learning rate: 0.001, batch size: 32\n",
            "True\n",
            "Fold 1, Epoch 1, F1 Score: 0.5804181163491933\n",
            "Fold 1, Epoch 2, F1 Score: 0.6015906261063725\n",
            "Fold 1, Epoch 3, F1 Score: 0.6147059343740789\n",
            "Fold 1, Epoch 4, F1 Score: 0.7092898957068207\n",
            "Fold 1, Epoch 5, F1 Score: 0.6944780524017036\n",
            "Fold 1, Epoch 6, F1 Score: 0.729028123100823\n",
            "Fold 1, Epoch 7, F1 Score: 0.7589068166981642\n",
            "Fold 1, Epoch 8, F1 Score: 0.7522300886659014\n",
            "Fold 1, Epoch 9, F1 Score: 0.5546282480526946\n",
            "Fold 1, Epoch 10, F1 Score: 0.7395837087596105\n",
            "True\n",
            "Fold 2, Epoch 1, F1 Score: 0.6053821511114921\n",
            "Fold 2, Epoch 2, F1 Score: 0.6033835530360835\n",
            "Fold 2, Epoch 3, F1 Score: 0.6527047430971503\n",
            "Fold 2, Epoch 4, F1 Score: 0.5273281879846695\n",
            "Fold 2, Epoch 5, F1 Score: 0.2857838214934032\n",
            "Fold 2, Epoch 6, F1 Score: 0.7256350259204031\n",
            "Fold 2, Epoch 7, F1 Score: 0.7331283014560951\n",
            "Fold 2, Epoch 8, F1 Score: 0.695354276735011\n",
            "Fold 2, Epoch 9, F1 Score: 0.7079495992434349\n",
            "Fold 2, Epoch 10, F1 Score: 0.7588148790059726\n",
            "True\n",
            "Fold 3, Epoch 1, F1 Score: 0.387251919738085\n",
            "Fold 3, Epoch 2, F1 Score: 0.6517372189558448\n",
            "Fold 3, Epoch 3, F1 Score: 0.6240279979048137\n",
            "Fold 3, Epoch 4, F1 Score: 0.649578562638523\n",
            "Fold 3, Epoch 5, F1 Score: 0.7014442980375598\n",
            "Fold 3, Epoch 6, F1 Score: 0.6457454261607731\n",
            "Fold 3, Epoch 7, F1 Score: 0.6999998388533172\n",
            "Fold 3, Epoch 8, F1 Score: 0.7302494012017693\n",
            "Fold 3, Epoch 9, F1 Score: 0.6884891045701966\n",
            "Fold 3, Epoch 10, F1 Score: 0.7215572579006282\n",
            "True\n",
            "Fold 4, Epoch 1, F1 Score: 0.5806946034347089\n",
            "Fold 4, Epoch 2, F1 Score: 0.6886375652833315\n",
            "Fold 4, Epoch 3, F1 Score: 0.7120093669260381\n",
            "Fold 4, Epoch 4, F1 Score: 0.6336051161161401\n",
            "Fold 4, Epoch 5, F1 Score: 0.68120255117818\n",
            "Fold 4, Epoch 6, F1 Score: 0.6118169271718058\n",
            "Fold 4, Epoch 7, F1 Score: 0.7348057868308642\n",
            "Fold 4, Epoch 8, F1 Score: 0.7402195862066514\n",
            "Fold 4, Epoch 9, F1 Score: 0.6947652926626658\n",
            "Fold 4, Epoch 10, F1 Score: 0.7235082964018318\n",
            "True\n",
            "Fold 5, Epoch 1, F1 Score: 0.6326479196064588\n",
            "Fold 5, Epoch 2, F1 Score: 0.6536845038904944\n",
            "Fold 5, Epoch 3, F1 Score: 0.6181987325001991\n",
            "Fold 5, Epoch 4, F1 Score: 0.6141712660549502\n",
            "Fold 5, Epoch 5, F1 Score: 0.6240841818833344\n",
            "Fold 5, Epoch 6, F1 Score: 0.6855685207253676\n",
            "Fold 5, Epoch 7, F1 Score: 0.711471809127371\n",
            "Fold 5, Epoch 8, F1 Score: 0.6960690970851245\n",
            "Fold 5, Epoch 9, F1 Score: 0.6640334990621551\n",
            "Fold 5, Epoch 10, F1 Score: 0.7249802555785813\n",
            "Training with optimizer: SGD, learning rate: 0.001, batch size: 32\n",
            "True\n",
            "Fold 1, Epoch 1, F1 Score: 0.5566838447556198\n",
            "Fold 1, Epoch 2, F1 Score: 0.6870160176829857\n",
            "Fold 1, Epoch 3, F1 Score: 0.7363443357900626\n",
            "Fold 1, Epoch 4, F1 Score: 0.7549171990881588\n",
            "Fold 1, Epoch 5, F1 Score: 0.7546014867379772\n",
            "Fold 1, Epoch 6, F1 Score: 0.7508477226181336\n",
            "Fold 1, Epoch 7, F1 Score: 0.7473681487111133\n",
            "Fold 1, Epoch 8, F1 Score: 0.7630782864205757\n",
            "Fold 1, Epoch 9, F1 Score: 0.7585262310816795\n",
            "Fold 1, Epoch 10, F1 Score: 0.7640783859773267\n",
            "True\n",
            "Fold 2, Epoch 1, F1 Score: 0.5886360251396483\n",
            "Fold 2, Epoch 2, F1 Score: 0.6819765443139424\n",
            "Fold 2, Epoch 3, F1 Score: 0.715800320662988\n",
            "Fold 2, Epoch 4, F1 Score: 0.7401693189864528\n",
            "Fold 2, Epoch 5, F1 Score: 0.7296404547859506\n",
            "Fold 2, Epoch 6, F1 Score: 0.7612862670795802\n",
            "Fold 2, Epoch 7, F1 Score: 0.7635378336484266\n",
            "Fold 2, Epoch 8, F1 Score: 0.7493321232387516\n",
            "Fold 2, Epoch 9, F1 Score: 0.7517328835813314\n",
            "Fold 2, Epoch 10, F1 Score: 0.7640883628758385\n",
            "True\n",
            "Fold 3, Epoch 1, F1 Score: 0.526506314836691\n",
            "Fold 3, Epoch 2, F1 Score: 0.6669874387156195\n",
            "Fold 3, Epoch 3, F1 Score: 0.7029074377206671\n",
            "Fold 3, Epoch 4, F1 Score: 0.7057518813996291\n",
            "Fold 3, Epoch 5, F1 Score: 0.7293962044867689\n",
            "Fold 3, Epoch 6, F1 Score: 0.7224140638006679\n",
            "Fold 3, Epoch 7, F1 Score: 0.7315291211154552\n",
            "Fold 3, Epoch 8, F1 Score: 0.7224068398693921\n",
            "Fold 3, Epoch 9, F1 Score: 0.7409641549388774\n",
            "Fold 3, Epoch 10, F1 Score: 0.7452686326037056\n",
            "True\n",
            "Fold 4, Epoch 1, F1 Score: 0.5399775731226409\n",
            "Fold 4, Epoch 2, F1 Score: 0.6676239302033453\n",
            "Fold 4, Epoch 3, F1 Score: 0.7224103753430943\n",
            "Fold 4, Epoch 4, F1 Score: 0.744174847997961\n",
            "Fold 4, Epoch 5, F1 Score: 0.7383745601904854\n",
            "Fold 4, Epoch 6, F1 Score: 0.7555285501045796\n",
            "Fold 4, Epoch 7, F1 Score: 0.7437123072305636\n",
            "Fold 4, Epoch 8, F1 Score: 0.7546469242169468\n",
            "Fold 4, Epoch 9, F1 Score: 0.7566512585833521\n",
            "Fold 4, Epoch 10, F1 Score: 0.7556147461730703\n",
            "True\n",
            "Fold 5, Epoch 1, F1 Score: 0.5832355797771801\n",
            "Fold 5, Epoch 2, F1 Score: 0.644403578689185\n",
            "Fold 5, Epoch 3, F1 Score: 0.6912952208362647\n",
            "Fold 5, Epoch 4, F1 Score: 0.7166080142481355\n",
            "Fold 5, Epoch 5, F1 Score: 0.7156850917011188\n",
            "Fold 5, Epoch 6, F1 Score: 0.7328344387760583\n",
            "Fold 5, Epoch 7, F1 Score: 0.7374649376257937\n",
            "Fold 5, Epoch 8, F1 Score: 0.7339378185389397\n",
            "Fold 5, Epoch 9, F1 Score: 0.7290241518830447\n",
            "Fold 5, Epoch 10, F1 Score: 0.7253448048226869\n",
            "Training with optimizer: RMSprop, learning rate: 0.001, batch size: 32\n",
            "True\n",
            "Fold 1, Epoch 1, F1 Score: 0.06728379556737261\n",
            "Fold 1, Epoch 2, F1 Score: 0.2005108149024679\n",
            "Fold 1, Epoch 3, F1 Score: 0.13328321249113328\n",
            "Fold 1, Epoch 4, F1 Score: 0.19615773249435334\n",
            "Fold 1, Epoch 5, F1 Score: 0.1040211169120459\n",
            "Fold 1, Epoch 6, F1 Score: 0.6329551274712087\n",
            "Fold 1, Epoch 7, F1 Score: 0.41848345011192084\n",
            "Fold 1, Epoch 8, F1 Score: 0.23430947136501779\n",
            "Fold 1, Epoch 9, F1 Score: 0.2349981258849485\n",
            "Fold 1, Epoch 10, F1 Score: 0.4771519786705735\n",
            "True\n",
            "Fold 2, Epoch 1, F1 Score: 0.23817301385273448\n",
            "Fold 2, Epoch 2, F1 Score: 0.09896820383238576\n",
            "Fold 2, Epoch 3, F1 Score: 0.2517423924771402\n",
            "Fold 2, Epoch 4, F1 Score: 0.5370709343132082\n",
            "Fold 2, Epoch 5, F1 Score: 0.2706693534823181\n",
            "Fold 2, Epoch 6, F1 Score: 0.3423110088241337\n",
            "Fold 2, Epoch 7, F1 Score: 0.32879476847813965\n",
            "Fold 2, Epoch 8, F1 Score: 0.20130889859805523\n",
            "Fold 2, Epoch 9, F1 Score: 0.6047618461300809\n",
            "Fold 2, Epoch 10, F1 Score: 0.5069528741427005\n",
            "True\n",
            "Fold 3, Epoch 1, F1 Score: 0.15576178456533712\n",
            "Fold 3, Epoch 2, F1 Score: 0.18276243129927303\n",
            "Fold 3, Epoch 3, F1 Score: 0.3429976762469742\n",
            "Fold 3, Epoch 4, F1 Score: 0.4424509961889766\n",
            "Fold 3, Epoch 5, F1 Score: 0.07738268723220842\n",
            "Fold 3, Epoch 6, F1 Score: 0.3330495551702219\n",
            "Fold 3, Epoch 7, F1 Score: 0.6164920236839717\n",
            "Fold 3, Epoch 8, F1 Score: 0.6354946512387911\n",
            "Fold 3, Epoch 9, F1 Score: 0.1510238094902548\n",
            "Fold 3, Epoch 10, F1 Score: 0.5944302699085074\n",
            "True\n",
            "Fold 4, Epoch 1, F1 Score: 0.061229488121479304\n",
            "Fold 4, Epoch 2, F1 Score: 0.16815518244528582\n",
            "Fold 4, Epoch 3, F1 Score: 0.2099733173901972\n",
            "Fold 4, Epoch 4, F1 Score: 0.13639330678811598\n",
            "Fold 4, Epoch 5, F1 Score: 0.5408780792353564\n",
            "Fold 4, Epoch 6, F1 Score: 0.5731747312535017\n",
            "Fold 4, Epoch 7, F1 Score: 0.26612245149318564\n",
            "Fold 4, Epoch 8, F1 Score: 0.520685737512835\n",
            "Fold 4, Epoch 9, F1 Score: 0.46172849844202174\n",
            "Fold 4, Epoch 10, F1 Score: 0.6378495461555306\n",
            "True\n",
            "Fold 5, Epoch 1, F1 Score: 0.18767649942691722\n",
            "Fold 5, Epoch 2, F1 Score: 0.25829845147579983\n",
            "Fold 5, Epoch 3, F1 Score: 0.0782921127883363\n",
            "Fold 5, Epoch 4, F1 Score: 0.19652862232527316\n",
            "Fold 5, Epoch 5, F1 Score: 0.21746525013090814\n",
            "Fold 5, Epoch 6, F1 Score: 0.5604923664181086\n",
            "Fold 5, Epoch 7, F1 Score: 0.489648854915066\n",
            "Fold 5, Epoch 8, F1 Score: 0.3055794076663782\n",
            "Fold 5, Epoch 9, F1 Score: 0.6504467046118113\n",
            "Fold 5, Epoch 10, F1 Score: 0.6023037971220138\n",
            "Training with optimizer: Adam, learning rate: 0.001, batch size: 64\n",
            "True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1, Epoch 1, F1 Score: 0.494345880415841\n",
            "Fold 1, Epoch 2, F1 Score: 0.698405654964858\n",
            "Fold 1, Epoch 3, F1 Score: 0.5421223958490567\n",
            "Fold 1, Epoch 4, F1 Score: 0.7069827099071949\n",
            "Fold 1, Epoch 5, F1 Score: 0.7169790732800796\n",
            "Fold 1, Epoch 6, F1 Score: 0.6740104284706474\n",
            "Fold 1, Epoch 7, F1 Score: 0.6637087430639167\n",
            "Fold 1, Epoch 8, F1 Score: 0.6608814278292904\n",
            "Fold 1, Epoch 9, F1 Score: 0.7391552778162082\n",
            "Fold 1, Epoch 10, F1 Score: 0.7313812797104972\n",
            "True\n",
            "Fold 2, Epoch 1, F1 Score: 0.6319143555917446\n",
            "Fold 2, Epoch 2, F1 Score: 0.7015796247829228\n",
            "Fold 2, Epoch 3, F1 Score: 0.6172155702927782\n",
            "Fold 2, Epoch 4, F1 Score: 0.6628841676270466\n",
            "Fold 2, Epoch 5, F1 Score: 0.655875952147994\n",
            "Fold 2, Epoch 6, F1 Score: 0.6777118375431667\n",
            "Fold 2, Epoch 7, F1 Score: 0.7748763641292403\n",
            "Fold 2, Epoch 8, F1 Score: 0.7404980509462312\n",
            "Fold 2, Epoch 9, F1 Score: 0.7117888432524332\n",
            "Fold 2, Epoch 10, F1 Score: 0.7397700017750294\n",
            "True\n",
            "Fold 3, Epoch 1, F1 Score: 0.5968791074634109\n",
            "Fold 3, Epoch 2, F1 Score: 0.6666515253338805\n",
            "Fold 3, Epoch 3, F1 Score: 0.5956742216092533\n",
            "Fold 3, Epoch 4, F1 Score: 0.6797212739455363\n",
            "Fold 3, Epoch 5, F1 Score: 0.6119181949796757\n",
            "Fold 3, Epoch 6, F1 Score: 0.6263834135837353\n",
            "Fold 3, Epoch 7, F1 Score: 0.6329522162814264\n",
            "Fold 3, Epoch 8, F1 Score: 0.6862909512320122\n",
            "Fold 3, Epoch 9, F1 Score: 0.6761949581225003\n",
            "Fold 3, Epoch 10, F1 Score: 0.7222147606823089\n",
            "True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4, Epoch 1, F1 Score: 0.5699933564919466\n",
            "Fold 4, Epoch 2, F1 Score: 0.6641864524437252\n",
            "Fold 4, Epoch 3, F1 Score: 0.6291192703696653\n",
            "Fold 4, Epoch 4, F1 Score: 0.65682721326365\n",
            "Fold 4, Epoch 5, F1 Score: 0.692203334783735\n",
            "Fold 4, Epoch 6, F1 Score: 0.5292004606021847\n",
            "Fold 4, Epoch 7, F1 Score: 0.6855584508983235\n",
            "Fold 4, Epoch 8, F1 Score: 0.7255828321779766\n",
            "Fold 4, Epoch 9, F1 Score: 0.7460886723846244\n",
            "Fold 4, Epoch 10, F1 Score: 0.759604039741058\n",
            "True\n",
            "Fold 5, Epoch 1, F1 Score: 0.5883320192663312\n",
            "Fold 5, Epoch 2, F1 Score: 0.5193335433594939\n",
            "Fold 5, Epoch 3, F1 Score: 0.6520712174258672\n",
            "Fold 5, Epoch 4, F1 Score: 0.6644157524655928\n",
            "Fold 5, Epoch 5, F1 Score: 0.6149888608073636\n",
            "Fold 5, Epoch 6, F1 Score: 0.6560386017724181\n",
            "Fold 5, Epoch 7, F1 Score: 0.7002186089583159\n",
            "Fold 5, Epoch 8, F1 Score: 0.7264774021822031\n",
            "Fold 5, Epoch 9, F1 Score: 0.7354978399848452\n",
            "Fold 5, Epoch 10, F1 Score: 0.6784720341778385\n",
            "Training with optimizer: SGD, learning rate: 0.001, batch size: 64\n",
            "True\n",
            "Fold 1, Epoch 1, F1 Score: 0.46895664491823447\n",
            "Fold 1, Epoch 2, F1 Score: 0.6001210816286192\n",
            "Fold 1, Epoch 3, F1 Score: 0.6773937393602291\n",
            "Fold 1, Epoch 4, F1 Score: 0.7145196007691613\n",
            "Fold 1, Epoch 5, F1 Score: 0.7282530212150844\n",
            "Fold 1, Epoch 6, F1 Score: 0.743111972544412\n",
            "Fold 1, Epoch 7, F1 Score: 0.7600158443231585\n",
            "Fold 1, Epoch 8, F1 Score: 0.763212487548217\n",
            "Fold 1, Epoch 9, F1 Score: 0.7670740855395369\n",
            "Fold 1, Epoch 10, F1 Score: 0.7508313584540094\n",
            "True\n",
            "Fold 2, Epoch 1, F1 Score: 0.415978696868272\n",
            "Fold 2, Epoch 2, F1 Score: 0.5809483629931275\n",
            "Fold 2, Epoch 3, F1 Score: 0.6159074654262845\n",
            "Fold 2, Epoch 4, F1 Score: 0.6599147940539206\n",
            "Fold 2, Epoch 5, F1 Score: 0.683295399221767\n",
            "Fold 2, Epoch 6, F1 Score: 0.6905438677073787\n",
            "Fold 2, Epoch 7, F1 Score: 0.6950032654882738\n",
            "Fold 2, Epoch 8, F1 Score: 0.7147102643085468\n",
            "Fold 2, Epoch 9, F1 Score: 0.7166973190365115\n",
            "Fold 2, Epoch 10, F1 Score: 0.7238143001116099\n",
            "True\n",
            "Fold 3, Epoch 1, F1 Score: 0.44457684897856736\n",
            "Fold 3, Epoch 2, F1 Score: 0.60660034979308\n",
            "Fold 3, Epoch 3, F1 Score: 0.6530142172873846\n",
            "Fold 3, Epoch 4, F1 Score: 0.7019450821258667\n",
            "Fold 3, Epoch 5, F1 Score: 0.7361318220973118\n",
            "Fold 3, Epoch 6, F1 Score: 0.72460356750348\n",
            "Fold 3, Epoch 7, F1 Score: 0.74140519354645\n",
            "Fold 3, Epoch 8, F1 Score: 0.7423458922616321\n",
            "Fold 3, Epoch 9, F1 Score: 0.721824619805559\n",
            "Fold 3, Epoch 10, F1 Score: 0.7297144854094162\n",
            "True\n",
            "Fold 4, Epoch 1, F1 Score: 0.46349917726063605\n",
            "Fold 4, Epoch 2, F1 Score: 0.5700377731024986\n",
            "Fold 4, Epoch 3, F1 Score: 0.6455880534289989\n",
            "Fold 4, Epoch 4, F1 Score: 0.6732284494449544\n",
            "Fold 4, Epoch 5, F1 Score: 0.7127266152128539\n",
            "Fold 4, Epoch 6, F1 Score: 0.7220794623736057\n",
            "Fold 4, Epoch 7, F1 Score: 0.7244086432391041\n",
            "Fold 4, Epoch 8, F1 Score: 0.7456994320375264\n",
            "Fold 4, Epoch 9, F1 Score: 0.742637287058488\n",
            "Fold 4, Epoch 10, F1 Score: 0.7519098743250386\n",
            "True\n",
            "Fold 5, Epoch 1, F1 Score: 0.44070273345260613\n",
            "Fold 5, Epoch 2, F1 Score: 0.5541537091164023\n",
            "Fold 5, Epoch 3, F1 Score: 0.6033080842875683\n",
            "Fold 5, Epoch 4, F1 Score: 0.6409231314348817\n",
            "Fold 5, Epoch 5, F1 Score: 0.6700343545754698\n",
            "Fold 5, Epoch 6, F1 Score: 0.7056879796569843\n",
            "Fold 5, Epoch 7, F1 Score: 0.6641674761403081\n",
            "Fold 5, Epoch 8, F1 Score: 0.6915392278797056\n",
            "Fold 5, Epoch 9, F1 Score: 0.6725524436157023\n",
            "Fold 5, Epoch 10, F1 Score: 0.7124850321513047\n",
            "Training with optimizer: RMSprop, learning rate: 0.001, batch size: 64\n",
            "True\n",
            "Fold 1, Epoch 1, F1 Score: 0.23672124136520423\n",
            "Fold 1, Epoch 2, F1 Score: 0.26436136396559745\n",
            "Fold 1, Epoch 3, F1 Score: 0.498448833421507\n",
            "Fold 1, Epoch 4, F1 Score: 0.3279683809544886\n",
            "Fold 1, Epoch 5, F1 Score: 0.5171734008107393\n",
            "Fold 1, Epoch 6, F1 Score: 0.5042702909762189\n",
            "Fold 1, Epoch 7, F1 Score: 0.6268146511102292\n",
            "Fold 1, Epoch 8, F1 Score: 0.6912239045051546\n",
            "Fold 1, Epoch 9, F1 Score: 0.4618409184535925\n",
            "Fold 1, Epoch 10, F1 Score: 0.5465126112453027\n",
            "True\n",
            "Fold 2, Epoch 1, F1 Score: 0.20807798155262358\n",
            "Fold 2, Epoch 2, F1 Score: 0.19982965057989963\n",
            "Fold 2, Epoch 3, F1 Score: 0.3493051839748092\n",
            "Fold 2, Epoch 4, F1 Score: 0.4312117059379286\n",
            "Fold 2, Epoch 5, F1 Score: 0.6443281399260784\n",
            "Fold 2, Epoch 6, F1 Score: 0.5711124359925969\n",
            "Fold 2, Epoch 7, F1 Score: 0.5505980166692971\n",
            "Fold 2, Epoch 8, F1 Score: 0.37287092090186597\n",
            "Fold 2, Epoch 9, F1 Score: 0.6377543316808183\n",
            "Fold 2, Epoch 10, F1 Score: 0.6388890433455404\n",
            "True\n",
            "Fold 3, Epoch 1, F1 Score: 0.10149103723776447\n",
            "Fold 3, Epoch 2, F1 Score: 0.3449390989300354\n",
            "Fold 3, Epoch 3, F1 Score: 0.2947791975090767\n",
            "Fold 3, Epoch 4, F1 Score: 0.3599088708145361\n",
            "Fold 3, Epoch 5, F1 Score: 0.564595037307365\n",
            "Fold 3, Epoch 6, F1 Score: 0.5583924329271586\n",
            "Fold 3, Epoch 7, F1 Score: 0.6491310358178972\n",
            "Fold 3, Epoch 8, F1 Score: 0.6645293593930972\n",
            "Fold 3, Epoch 9, F1 Score: 0.6534463362104037\n",
            "Fold 3, Epoch 10, F1 Score: 0.6846686009379269\n",
            "True\n",
            "Fold 4, Epoch 1, F1 Score: 0.21465801258130868\n",
            "Fold 4, Epoch 2, F1 Score: 0.301424806137998\n",
            "Fold 4, Epoch 3, F1 Score: 0.39882913274252796\n",
            "Fold 4, Epoch 4, F1 Score: 0.5869967310104997\n",
            "Fold 4, Epoch 5, F1 Score: 0.5631922030443134\n",
            "Fold 4, Epoch 6, F1 Score: 0.5811325881465814\n",
            "Fold 4, Epoch 7, F1 Score: 0.6822156720337101\n",
            "Fold 4, Epoch 8, F1 Score: 0.5815812588979415\n",
            "Fold 4, Epoch 9, F1 Score: 0.6947292989038444\n",
            "Fold 4, Epoch 10, F1 Score: 0.5129908508708693\n",
            "True\n",
            "Fold 5, Epoch 1, F1 Score: 0.21934729361212899\n",
            "Fold 5, Epoch 2, F1 Score: 0.27574496056091147\n",
            "Fold 5, Epoch 3, F1 Score: 0.38006075129420336\n",
            "Fold 5, Epoch 4, F1 Score: 0.47497021785129806\n",
            "Fold 5, Epoch 5, F1 Score: 0.5387507063226958\n",
            "Fold 5, Epoch 6, F1 Score: 0.5963559132508668\n",
            "Fold 5, Epoch 7, F1 Score: 0.37573787871837006\n",
            "Fold 5, Epoch 8, F1 Score: 0.5756999578130579\n",
            "Fold 5, Epoch 9, F1 Score: 0.6260996092544345\n",
            "Fold 5, Epoch 10, F1 Score: 0.607335302032301\n",
            "Training with optimizer: Adam, learning rate: 0.001, batch size: 128\n",
            "True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1, Epoch 1, F1 Score: 0.6668641444456109\n",
            "Fold 1, Epoch 2, F1 Score: 0.5937283077344528\n",
            "Fold 1, Epoch 3, F1 Score: 0.6574287845245431\n",
            "Fold 1, Epoch 4, F1 Score: 0.727634664650509\n",
            "Fold 1, Epoch 5, F1 Score: 0.716149715230809\n",
            "Fold 1, Epoch 6, F1 Score: 0.7100861179751989\n",
            "Fold 1, Epoch 7, F1 Score: 0.7356056007875732\n",
            "Fold 1, Epoch 8, F1 Score: 0.7456811192163167\n",
            "Fold 1, Epoch 9, F1 Score: 0.5965359070369819\n",
            "Fold 1, Epoch 10, F1 Score: 0.6979353061766919\n",
            "True\n",
            "Fold 2, Epoch 1, F1 Score: 0.6648344671832523\n",
            "Fold 2, Epoch 2, F1 Score: 0.6756689793080161\n",
            "Fold 2, Epoch 3, F1 Score: 0.6084026922892463\n",
            "Fold 2, Epoch 4, F1 Score: 0.6552560272050398\n",
            "Fold 2, Epoch 5, F1 Score: 0.7626010839223295\n",
            "Fold 2, Epoch 6, F1 Score: 0.7309639421683684\n",
            "Fold 2, Epoch 7, F1 Score: 0.7085274764194497\n",
            "Fold 2, Epoch 8, F1 Score: 0.6866166359860606\n",
            "Fold 2, Epoch 9, F1 Score: 0.7367980395005637\n",
            "Fold 2, Epoch 10, F1 Score: 0.7257112879066638\n",
            "True\n",
            "Fold 3, Epoch 1, F1 Score: 0.6337785473091181\n",
            "Fold 3, Epoch 2, F1 Score: 0.6041524559645871\n",
            "Fold 3, Epoch 3, F1 Score: 0.6735329613873926\n",
            "Fold 3, Epoch 4, F1 Score: 0.6374363594946523\n",
            "Fold 3, Epoch 5, F1 Score: 0.7370715658106642\n",
            "Fold 3, Epoch 6, F1 Score: 0.6654805191964422\n",
            "Fold 3, Epoch 7, F1 Score: 0.7244228069040721\n",
            "Fold 3, Epoch 8, F1 Score: 0.735664598031791\n",
            "Fold 3, Epoch 9, F1 Score: 0.6888727948097567\n",
            "Fold 3, Epoch 10, F1 Score: 0.5769216092404809\n",
            "True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4, Epoch 1, F1 Score: 0.6389538506746694\n",
            "Fold 4, Epoch 2, F1 Score: 0.5853502133953152\n",
            "Fold 4, Epoch 3, F1 Score: 0.7110700933120305\n",
            "Fold 4, Epoch 4, F1 Score: 0.7098214193473026\n",
            "Fold 4, Epoch 5, F1 Score: 0.7011396832824971\n",
            "Fold 4, Epoch 6, F1 Score: 0.6337288587932889\n",
            "Fold 4, Epoch 7, F1 Score: 0.7169870256124425\n",
            "Fold 4, Epoch 8, F1 Score: 0.7352709146717267\n",
            "Fold 4, Epoch 9, F1 Score: 0.7800296514010704\n",
            "Fold 4, Epoch 10, F1 Score: 0.6532785427032013\n",
            "True\n",
            "Fold 5, Epoch 1, F1 Score: 0.6430881364078912\n",
            "Fold 5, Epoch 2, F1 Score: 0.7458367735552018\n",
            "Fold 5, Epoch 3, F1 Score: 0.7172541858225129\n",
            "Fold 5, Epoch 4, F1 Score: 0.714685519376724\n",
            "Fold 5, Epoch 5, F1 Score: 0.6924959355656793\n",
            "Fold 5, Epoch 6, F1 Score: 0.7043948980044274\n",
            "Fold 5, Epoch 7, F1 Score: 0.6182839287750016\n",
            "Fold 5, Epoch 8, F1 Score: 0.7302518732092068\n",
            "Fold 5, Epoch 9, F1 Score: 0.707701776593956\n",
            "Fold 5, Epoch 10, F1 Score: 0.7346124394698057\n",
            "Training with optimizer: SGD, learning rate: 0.001, batch size: 128\n",
            "True\n",
            "Fold 1, Epoch 1, F1 Score: 0.33046714905399077\n",
            "Fold 1, Epoch 2, F1 Score: 0.4572872641422308\n",
            "Fold 1, Epoch 3, F1 Score: 0.5287182704132906\n",
            "Fold 1, Epoch 4, F1 Score: 0.5929547205272963\n",
            "Fold 1, Epoch 5, F1 Score: 0.616115271354222\n",
            "Fold 1, Epoch 6, F1 Score: 0.6603150906071652\n",
            "Fold 1, Epoch 7, F1 Score: 0.6834482851229707\n",
            "Fold 1, Epoch 8, F1 Score: 0.6879773093386249\n",
            "Fold 1, Epoch 9, F1 Score: 0.7187839161932579\n",
            "Fold 1, Epoch 10, F1 Score: 0.7434631175891603\n",
            "True\n",
            "Fold 2, Epoch 1, F1 Score: 0.28518797266785895\n",
            "Fold 2, Epoch 2, F1 Score: 0.40391731909070067\n",
            "Fold 2, Epoch 3, F1 Score: 0.5127321044598102\n",
            "Fold 2, Epoch 4, F1 Score: 0.5769666352064106\n",
            "Fold 2, Epoch 5, F1 Score: 0.5929666132581818\n",
            "Fold 2, Epoch 6, F1 Score: 0.6260080527614583\n",
            "Fold 2, Epoch 7, F1 Score: 0.6773389162201418\n",
            "Fold 2, Epoch 8, F1 Score: 0.6548387236858264\n",
            "Fold 2, Epoch 9, F1 Score: 0.691591429598111\n",
            "Fold 2, Epoch 10, F1 Score: 0.6937210085265894\n",
            "True\n",
            "Fold 3, Epoch 1, F1 Score: 0.33007863669142057\n",
            "Fold 3, Epoch 2, F1 Score: 0.4135694644637979\n",
            "Fold 3, Epoch 3, F1 Score: 0.5386392874498648\n",
            "Fold 3, Epoch 4, F1 Score: 0.5595302701988487\n",
            "Fold 3, Epoch 5, F1 Score: 0.5801421455969106\n",
            "Fold 3, Epoch 6, F1 Score: 0.6482318299945112\n",
            "Fold 3, Epoch 7, F1 Score: 0.6653074646750144\n",
            "Fold 3, Epoch 8, F1 Score: 0.6639200775872861\n",
            "Fold 3, Epoch 9, F1 Score: 0.6826905043335173\n",
            "Fold 3, Epoch 10, F1 Score: 0.671925161928644\n",
            "True\n",
            "Fold 4, Epoch 1, F1 Score: 0.34271790456666124\n",
            "Fold 4, Epoch 2, F1 Score: 0.48252756071322606\n",
            "Fold 4, Epoch 3, F1 Score: 0.542339501166172\n",
            "Fold 4, Epoch 4, F1 Score: 0.6069775004629432\n",
            "Fold 4, Epoch 5, F1 Score: 0.6601293564072556\n",
            "Fold 4, Epoch 6, F1 Score: 0.6809438592633761\n",
            "Fold 4, Epoch 7, F1 Score: 0.6798685578164667\n",
            "Fold 4, Epoch 8, F1 Score: 0.6816279638102607\n",
            "Fold 4, Epoch 9, F1 Score: 0.6952405028028967\n",
            "Fold 4, Epoch 10, F1 Score: 0.7145483455313619\n",
            "True\n",
            "Fold 5, Epoch 1, F1 Score: 0.3497774386911648\n",
            "Fold 5, Epoch 2, F1 Score: 0.4640732995299898\n",
            "Fold 5, Epoch 3, F1 Score: 0.5380942035844436\n",
            "Fold 5, Epoch 4, F1 Score: 0.5647702248983664\n",
            "Fold 5, Epoch 5, F1 Score: 0.632092911797022\n",
            "Fold 5, Epoch 6, F1 Score: 0.6379995516898748\n",
            "Fold 5, Epoch 7, F1 Score: 0.6586041156233308\n",
            "Fold 5, Epoch 8, F1 Score: 0.6527815588001536\n",
            "Fold 5, Epoch 9, F1 Score: 0.679872683497219\n",
            "Fold 5, Epoch 10, F1 Score: 0.6964138464366559\n",
            "Training with optimizer: RMSprop, learning rate: 0.001, batch size: 128\n",
            "True\n",
            "Fold 1, Epoch 1, F1 Score: 0.09896820383238576\n",
            "Fold 1, Epoch 2, F1 Score: 0.18028300103537334\n",
            "Fold 1, Epoch 3, F1 Score: 0.24471318225582706\n",
            "Fold 1, Epoch 4, F1 Score: 0.5148023684317516\n",
            "Fold 1, Epoch 5, F1 Score: 0.4085782547150965\n",
            "Fold 1, Epoch 6, F1 Score: 0.43051015467863046\n",
            "Fold 1, Epoch 7, F1 Score: 0.5183718947631808\n",
            "Fold 1, Epoch 8, F1 Score: 0.676488409053348\n",
            "Fold 1, Epoch 9, F1 Score: 0.5402541379341746\n",
            "Fold 1, Epoch 10, F1 Score: 0.5153957294773662\n",
            "True\n",
            "Fold 2, Epoch 1, F1 Score: 0.23143261369288717\n",
            "Fold 2, Epoch 2, F1 Score: 0.33463878605868586\n",
            "Fold 2, Epoch 3, F1 Score: 0.274939200926462\n",
            "Fold 2, Epoch 4, F1 Score: 0.49764067000845597\n",
            "Fold 2, Epoch 5, F1 Score: 0.5263612537470953\n",
            "Fold 2, Epoch 6, F1 Score: 0.536243269522645\n",
            "Fold 2, Epoch 7, F1 Score: 0.5605167979319927\n",
            "Fold 2, Epoch 8, F1 Score: 0.5177231593944369\n",
            "Fold 2, Epoch 9, F1 Score: 0.43739073410892376\n",
            "Fold 2, Epoch 10, F1 Score: 0.7446822039743003\n",
            "True\n",
            "Fold 3, Epoch 1, F1 Score: 0.20933607656370867\n",
            "Fold 3, Epoch 2, F1 Score: 0.47600735550751194\n",
            "Fold 3, Epoch 3, F1 Score: 0.39313119586303635\n",
            "Fold 3, Epoch 4, F1 Score: 0.6199591575091744\n",
            "Fold 3, Epoch 5, F1 Score: 0.5326180178504375\n",
            "Fold 3, Epoch 6, F1 Score: 0.5817100429412211\n",
            "Fold 3, Epoch 7, F1 Score: 0.6873511906441583\n",
            "Fold 3, Epoch 8, F1 Score: 0.7110152629182301\n",
            "Fold 3, Epoch 9, F1 Score: 0.6734936799990322\n",
            "Fold 3, Epoch 10, F1 Score: 0.7127394496178621\n",
            "True\n",
            "Fold 4, Epoch 1, F1 Score: 0.14331663712722506\n",
            "Fold 4, Epoch 2, F1 Score: 0.2440845220282355\n",
            "Fold 4, Epoch 3, F1 Score: 0.2417682234280896\n",
            "Fold 4, Epoch 4, F1 Score: 0.48785796198694636\n",
            "Fold 4, Epoch 5, F1 Score: 0.47321064749297775\n",
            "Fold 4, Epoch 6, F1 Score: 0.5776699524793515\n",
            "Fold 4, Epoch 7, F1 Score: 0.6142574970484947\n",
            "Fold 4, Epoch 8, F1 Score: 0.4829079977127366\n",
            "Fold 4, Epoch 9, F1 Score: 0.5483474221473975\n",
            "Fold 4, Epoch 10, F1 Score: 0.6580245918185769\n",
            "True\n",
            "Fold 5, Epoch 1, F1 Score: 0.09888256377819944\n",
            "Fold 5, Epoch 2, F1 Score: 0.32298112276925833\n",
            "Fold 5, Epoch 3, F1 Score: 0.38942090284605707\n",
            "Fold 5, Epoch 4, F1 Score: 0.5038472842353748\n",
            "Fold 5, Epoch 5, F1 Score: 0.41870498002426726\n",
            "Fold 5, Epoch 6, F1 Score: 0.4289357973733405\n",
            "Fold 5, Epoch 7, F1 Score: 0.5028961472308161\n",
            "Fold 5, Epoch 8, F1 Score: 0.6140627927644412\n",
            "Fold 5, Epoch 9, F1 Score: 0.6340350452285627\n",
            "Fold 5, Epoch 10, F1 Score: 0.5790272384381376\n",
            "Training with optimizer: Adam, learning rate: 0.0001, batch size: 32\n",
            "True\n",
            "Fold 1, Epoch 1, F1 Score: 0.7308687922131099\n",
            "Fold 1, Epoch 2, F1 Score: 0.7596160374702388\n",
            "Fold 1, Epoch 3, F1 Score: 0.77712853332426\n",
            "Fold 1, Epoch 4, F1 Score: 0.7905198919497458\n",
            "Fold 1, Epoch 5, F1 Score: 0.7925616492686819\n",
            "Fold 1, Epoch 6, F1 Score: 0.799721166886291\n",
            "Fold 1, Epoch 7, F1 Score: 0.775741538298404\n",
            "Fold 1, Epoch 8, F1 Score: 0.7925166861849489\n",
            "Fold 1, Epoch 9, F1 Score: 0.7400669862428519\n",
            "Fold 1, Epoch 10, F1 Score: 0.7906252853001172\n",
            "True\n",
            "Fold 2, Epoch 1, F1 Score: 0.7205669743428779\n",
            "Fold 2, Epoch 2, F1 Score: 0.7882655225683504\n",
            "Fold 2, Epoch 3, F1 Score: 0.7753827759593844\n",
            "Fold 2, Epoch 4, F1 Score: 0.7624906517019941\n",
            "Fold 2, Epoch 5, F1 Score: 0.7760474892097298\n",
            "Fold 2, Epoch 6, F1 Score: 0.7891841335966506\n",
            "Fold 2, Epoch 7, F1 Score: 0.766576503065969\n",
            "Fold 2, Epoch 8, F1 Score: 0.7955022479279609\n",
            "Fold 2, Epoch 9, F1 Score: 0.8161588885858492\n",
            "Fold 2, Epoch 10, F1 Score: 0.7867669976841136\n",
            "True\n",
            "Fold 3, Epoch 1, F1 Score: 0.7021874119766432\n",
            "Fold 3, Epoch 2, F1 Score: 0.7067504479992258\n",
            "Fold 3, Epoch 3, F1 Score: 0.7483992521938375\n",
            "Fold 3, Epoch 4, F1 Score: 0.7588634532314239\n",
            "Fold 3, Epoch 5, F1 Score: 0.7605268945674374\n",
            "Fold 3, Epoch 6, F1 Score: 0.7631245638465499\n",
            "Fold 3, Epoch 7, F1 Score: 0.7272817658259983\n",
            "Fold 3, Epoch 8, F1 Score: 0.736545132371255\n",
            "Fold 3, Epoch 9, F1 Score: 0.766254858822819\n",
            "Fold 3, Epoch 10, F1 Score: 0.7544921753668259\n",
            "True\n",
            "Fold 4, Epoch 1, F1 Score: 0.7358906725401021\n",
            "Fold 4, Epoch 2, F1 Score: 0.8032058969634664\n",
            "Fold 4, Epoch 3, F1 Score: 0.7681430171276727\n",
            "Fold 4, Epoch 4, F1 Score: 0.778777059106091\n",
            "Fold 4, Epoch 5, F1 Score: 0.7819550038477497\n",
            "Fold 4, Epoch 6, F1 Score: 0.7738787413119056\n",
            "Fold 4, Epoch 7, F1 Score: 0.7856206985822718\n",
            "Fold 4, Epoch 8, F1 Score: 0.7726901975553484\n",
            "Fold 4, Epoch 9, F1 Score: 0.7923962605786187\n",
            "Fold 4, Epoch 10, F1 Score: 0.8035774233766708\n",
            "True\n",
            "Fold 5, Epoch 1, F1 Score: 0.7318094956705227\n",
            "Fold 5, Epoch 2, F1 Score: 0.7387798193698553\n",
            "Fold 5, Epoch 3, F1 Score: 0.7601348425561976\n",
            "Fold 5, Epoch 4, F1 Score: 0.7583165027946452\n",
            "Fold 5, Epoch 5, F1 Score: 0.7539163251806639\n",
            "Fold 5, Epoch 6, F1 Score: 0.7823715972683475\n",
            "Fold 5, Epoch 7, F1 Score: 0.7775447205401668\n",
            "Fold 5, Epoch 8, F1 Score: 0.7704628153427193\n",
            "Fold 5, Epoch 9, F1 Score: 0.763495298639413\n",
            "Fold 5, Epoch 10, F1 Score: 0.7783085712204386\n",
            "Training with optimizer: SGD, learning rate: 0.0001, batch size: 32\n",
            "True\n",
            "Fold 1, Epoch 1, F1 Score: 0.29135400890357516\n",
            "Fold 1, Epoch 2, F1 Score: 0.3339276364708315\n",
            "Fold 1, Epoch 3, F1 Score: 0.38855215376175806\n",
            "Fold 1, Epoch 4, F1 Score: 0.43373005584948393\n",
            "Fold 1, Epoch 5, F1 Score: 0.45293309414714544\n",
            "Fold 1, Epoch 6, F1 Score: 0.5148273293124969\n",
            "Fold 1, Epoch 7, F1 Score: 0.5480498420121306\n",
            "Fold 1, Epoch 8, F1 Score: 0.5962186224569085\n",
            "Fold 1, Epoch 9, F1 Score: 0.6021371746782105\n",
            "Fold 1, Epoch 10, F1 Score: 0.5971170332652771\n",
            "True\n",
            "Fold 2, Epoch 1, F1 Score: 0.28348476493015734\n",
            "Fold 2, Epoch 2, F1 Score: 0.3117554768504087\n",
            "Fold 2, Epoch 3, F1 Score: 0.37949112426580944\n",
            "Fold 2, Epoch 4, F1 Score: 0.43219688811592577\n",
            "Fold 2, Epoch 5, F1 Score: 0.4692045546572592\n",
            "Fold 2, Epoch 6, F1 Score: 0.5171957793803915\n",
            "Fold 2, Epoch 7, F1 Score: 0.5421080934270605\n",
            "Fold 2, Epoch 8, F1 Score: 0.5445732994456521\n",
            "Fold 2, Epoch 9, F1 Score: 0.5796760465244947\n",
            "Fold 2, Epoch 10, F1 Score: 0.6519354868639461\n",
            "True\n",
            "Fold 3, Epoch 1, F1 Score: 0.2764008280475346\n",
            "Fold 3, Epoch 2, F1 Score: 0.32138288609049304\n",
            "Fold 3, Epoch 3, F1 Score: 0.3551017805641079\n",
            "Fold 3, Epoch 4, F1 Score: 0.42956398198379625\n",
            "Fold 3, Epoch 5, F1 Score: 0.47896413057673975\n",
            "Fold 3, Epoch 6, F1 Score: 0.5162706668090017\n",
            "Fold 3, Epoch 7, F1 Score: 0.5323782117222321\n",
            "Fold 3, Epoch 8, F1 Score: 0.5320602567778815\n",
            "Fold 3, Epoch 9, F1 Score: 0.5638532677986516\n",
            "Fold 3, Epoch 10, F1 Score: 0.5636338209111365\n",
            "True\n",
            "Fold 4, Epoch 1, F1 Score: 0.2790859443087166\n",
            "Fold 4, Epoch 2, F1 Score: 0.31838769039867204\n",
            "Fold 4, Epoch 3, F1 Score: 0.37654471226121916\n",
            "Fold 4, Epoch 4, F1 Score: 0.4554932883643912\n",
            "Fold 4, Epoch 5, F1 Score: 0.4863737085562221\n",
            "Fold 4, Epoch 6, F1 Score: 0.5375682701063501\n",
            "Fold 4, Epoch 7, F1 Score: 0.523203194811721\n",
            "Fold 4, Epoch 8, F1 Score: 0.5652056659069813\n",
            "Fold 4, Epoch 9, F1 Score: 0.5875177950193603\n",
            "Fold 4, Epoch 10, F1 Score: 0.6073428255960737\n",
            "True\n",
            "Fold 5, Epoch 1, F1 Score: 0.3090358152121124\n",
            "Fold 5, Epoch 2, F1 Score: 0.36009783554787084\n",
            "Fold 5, Epoch 3, F1 Score: 0.4165549234286116\n",
            "Fold 5, Epoch 4, F1 Score: 0.45950023282097296\n",
            "Fold 5, Epoch 5, F1 Score: 0.5188972610029854\n",
            "Fold 5, Epoch 6, F1 Score: 0.5391957676709224\n",
            "Fold 5, Epoch 7, F1 Score: 0.5548345308566774\n",
            "Fold 5, Epoch 8, F1 Score: 0.5734082504341164\n",
            "Fold 5, Epoch 9, F1 Score: 0.5872801746691226\n",
            "Fold 5, Epoch 10, F1 Score: 0.5998170673665099\n",
            "Training with optimizer: RMSprop, learning rate: 0.0001, batch size: 32\n",
            "True\n",
            "Fold 1, Epoch 1, F1 Score: 0.5400970900672645\n",
            "Fold 1, Epoch 2, F1 Score: 0.7870418666703808\n",
            "Fold 1, Epoch 3, F1 Score: 0.6999230662421067\n",
            "Fold 1, Epoch 4, F1 Score: 0.6862594152783393\n",
            "Fold 1, Epoch 5, F1 Score: 0.7975277058914569\n",
            "Fold 1, Epoch 6, F1 Score: 0.7620818300140008\n",
            "Fold 1, Epoch 7, F1 Score: 0.6957486520523651\n",
            "Fold 1, Epoch 8, F1 Score: 0.7899118440335112\n",
            "Fold 1, Epoch 9, F1 Score: 0.7045791328397802\n",
            "Fold 1, Epoch 10, F1 Score: 0.7984091004974703\n",
            "True\n",
            "Fold 2, Epoch 1, F1 Score: 0.7466257612743005\n",
            "Fold 2, Epoch 2, F1 Score: 0.6925767469982848\n",
            "Fold 2, Epoch 3, F1 Score: 0.6956308965143733\n",
            "Fold 2, Epoch 4, F1 Score: 0.5709251760937536\n",
            "Fold 2, Epoch 5, F1 Score: 0.7120865072476761\n",
            "Fold 2, Epoch 6, F1 Score: 0.7434832125914436\n",
            "Fold 2, Epoch 7, F1 Score: 0.629184790161317\n",
            "Fold 2, Epoch 8, F1 Score: 0.6658802296126266\n",
            "Fold 2, Epoch 9, F1 Score: 0.7415237879876813\n",
            "Fold 2, Epoch 10, F1 Score: 0.6259996283370048\n",
            "True\n",
            "Fold 3, Epoch 1, F1 Score: 0.6840717510878994\n",
            "Fold 3, Epoch 2, F1 Score: 0.6773961572515818\n",
            "Fold 3, Epoch 3, F1 Score: 0.7618095281611642\n",
            "Fold 3, Epoch 4, F1 Score: 0.7724215456965967\n",
            "Fold 3, Epoch 5, F1 Score: 0.7521775964415282\n",
            "Fold 3, Epoch 6, F1 Score: 0.6053311020496632\n",
            "Fold 3, Epoch 7, F1 Score: 0.6817955792190422\n",
            "Fold 3, Epoch 8, F1 Score: 0.6393180844391059\n",
            "Fold 3, Epoch 9, F1 Score: 0.6503117407901178\n",
            "Fold 3, Epoch 10, F1 Score: 0.700268968134019\n",
            "True\n",
            "Fold 4, Epoch 1, F1 Score: 0.6809923774312098\n",
            "Fold 4, Epoch 2, F1 Score: 0.7502976312332037\n",
            "Fold 4, Epoch 3, F1 Score: 0.710158457986143\n",
            "Fold 4, Epoch 4, F1 Score: 0.6883937709477709\n",
            "Fold 4, Epoch 5, F1 Score: 0.7176618455954548\n",
            "Fold 4, Epoch 6, F1 Score: 0.4773906407255451\n",
            "Fold 4, Epoch 7, F1 Score: 0.7232985626790112\n",
            "Fold 4, Epoch 8, F1 Score: 0.7619939233768976\n",
            "Fold 4, Epoch 9, F1 Score: 0.769117372283756\n",
            "Fold 4, Epoch 10, F1 Score: 0.5894509382882295\n",
            "True\n",
            "Fold 5, Epoch 1, F1 Score: 0.6519859018780515\n",
            "Fold 5, Epoch 2, F1 Score: 0.6240917935605769\n",
            "Fold 5, Epoch 3, F1 Score: 0.6699637079804885\n",
            "Fold 5, Epoch 4, F1 Score: 0.6838948903912225\n",
            "Fold 5, Epoch 5, F1 Score: 0.7154464739711778\n",
            "Fold 5, Epoch 6, F1 Score: 0.8122594877400084\n",
            "Fold 5, Epoch 7, F1 Score: 0.6208884404921525\n",
            "Fold 5, Epoch 8, F1 Score: 0.790675816668431\n",
            "Fold 5, Epoch 9, F1 Score: 0.5914851693707917\n",
            "Fold 5, Epoch 10, F1 Score: 0.7552077912071842\n",
            "Training with optimizer: Adam, learning rate: 0.0001, batch size: 64\n",
            "True\n",
            "Fold 1, Epoch 1, F1 Score: 0.7297507172729524\n",
            "Fold 1, Epoch 2, F1 Score: 0.8043211736876178\n",
            "Fold 1, Epoch 3, F1 Score: 0.7981679728225134\n",
            "Fold 1, Epoch 4, F1 Score: 0.788299233241395\n",
            "Fold 1, Epoch 5, F1 Score: 0.7844056439093016\n",
            "Fold 1, Epoch 6, F1 Score: 0.7788211490122755\n",
            "Fold 1, Epoch 7, F1 Score: 0.7734455469063741\n",
            "Fold 1, Epoch 8, F1 Score: 0.7826910330631583\n",
            "Fold 1, Epoch 9, F1 Score: 0.797858510909048\n",
            "Fold 1, Epoch 10, F1 Score: 0.7898969706802772\n",
            "True\n",
            "Fold 2, Epoch 1, F1 Score: 0.7201699787257051\n",
            "Fold 2, Epoch 2, F1 Score: 0.763913543796634\n",
            "Fold 2, Epoch 3, F1 Score: 0.7551569701138506\n",
            "Fold 2, Epoch 4, F1 Score: 0.7681458001929379\n",
            "Fold 2, Epoch 5, F1 Score: 0.7722206353693837\n",
            "Fold 2, Epoch 6, F1 Score: 0.7662307936225385\n",
            "Fold 2, Epoch 7, F1 Score: 0.7659916054675437\n",
            "Fold 2, Epoch 8, F1 Score: 0.7611841447554041\n",
            "Fold 2, Epoch 9, F1 Score: 0.7726389730410764\n",
            "Fold 2, Epoch 10, F1 Score: 0.7838636951971285\n",
            "True\n",
            "Fold 3, Epoch 1, F1 Score: 0.676309432985497\n",
            "Fold 3, Epoch 2, F1 Score: 0.7205432411659668\n",
            "Fold 3, Epoch 3, F1 Score: 0.7455891055293554\n",
            "Fold 3, Epoch 4, F1 Score: 0.7278545758685295\n",
            "Fold 3, Epoch 5, F1 Score: 0.7337512153217323\n",
            "Fold 3, Epoch 6, F1 Score: 0.7419314149495522\n",
            "Fold 3, Epoch 7, F1 Score: 0.7501668892036149\n",
            "Fold 3, Epoch 8, F1 Score: 0.7537587337980094\n",
            "Fold 3, Epoch 9, F1 Score: 0.7462799913774526\n",
            "Fold 3, Epoch 10, F1 Score: 0.7301371327408881\n",
            "True\n",
            "Fold 4, Epoch 1, F1 Score: 0.6976612784321244\n",
            "Fold 4, Epoch 2, F1 Score: 0.7296998275171699\n",
            "Fold 4, Epoch 3, F1 Score: 0.731623891539461\n",
            "Fold 4, Epoch 4, F1 Score: 0.7501858615166915\n",
            "Fold 4, Epoch 5, F1 Score: 0.7508369332955621\n",
            "Fold 4, Epoch 6, F1 Score: 0.7658404360275958\n",
            "Fold 4, Epoch 7, F1 Score: 0.7517671784069417\n",
            "Fold 4, Epoch 8, F1 Score: 0.7506538328793653\n",
            "Fold 4, Epoch 9, F1 Score: 0.7663024733941167\n",
            "Fold 4, Epoch 10, F1 Score: 0.7454316566917699\n",
            "True\n",
            "Fold 5, Epoch 1, F1 Score: 0.6916892174340887\n",
            "Fold 5, Epoch 2, F1 Score: 0.7275963390772349\n",
            "Fold 5, Epoch 3, F1 Score: 0.740856568280669\n",
            "Fold 5, Epoch 4, F1 Score: 0.736409216737221\n",
            "Fold 5, Epoch 5, F1 Score: 0.7357065584177641\n",
            "Fold 5, Epoch 6, F1 Score: 0.7293400112381034\n",
            "Fold 5, Epoch 7, F1 Score: 0.7364257440320969\n",
            "Fold 5, Epoch 8, F1 Score: 0.7476995402135646\n",
            "Fold 5, Epoch 9, F1 Score: 0.7298016891025423\n",
            "Fold 5, Epoch 10, F1 Score: 0.7205802160669604\n",
            "Training with optimizer: SGD, learning rate: 0.0001, batch size: 64\n",
            "True\n",
            "Fold 1, Epoch 1, F1 Score: 0.25853648729936923\n",
            "Fold 1, Epoch 2, F1 Score: 0.301260094791656\n",
            "Fold 1, Epoch 3, F1 Score: 0.32417054156842573\n",
            "Fold 1, Epoch 4, F1 Score: 0.33881741291780404\n",
            "Fold 1, Epoch 5, F1 Score: 0.37802670893152124\n",
            "Fold 1, Epoch 6, F1 Score: 0.37531127571717976\n",
            "Fold 1, Epoch 7, F1 Score: 0.41910398104534363\n",
            "Fold 1, Epoch 8, F1 Score: 0.44835903863323007\n",
            "Fold 1, Epoch 9, F1 Score: 0.4589404491461368\n",
            "Fold 1, Epoch 10, F1 Score: 0.48292897550762715\n",
            "True\n",
            "Fold 2, Epoch 1, F1 Score: 0.26539996754479667\n",
            "Fold 2, Epoch 2, F1 Score: 0.3030399906031393\n",
            "Fold 2, Epoch 3, F1 Score: 0.33946719485602833\n",
            "Fold 2, Epoch 4, F1 Score: 0.36521944889315816\n",
            "Fold 2, Epoch 5, F1 Score: 0.411582919564623\n",
            "Fold 2, Epoch 6, F1 Score: 0.4365192447088632\n",
            "Fold 2, Epoch 7, F1 Score: 0.4563497983849811\n",
            "Fold 2, Epoch 8, F1 Score: 0.4695692626688553\n",
            "Fold 2, Epoch 9, F1 Score: 0.48502794166873614\n",
            "Fold 2, Epoch 10, F1 Score: 0.5171290028462777\n",
            "True\n",
            "Fold 3, Epoch 1, F1 Score: 0.2517305510235597\n",
            "Fold 3, Epoch 2, F1 Score: 0.2957961477060227\n",
            "Fold 3, Epoch 3, F1 Score: 0.3253659230633977\n",
            "Fold 3, Epoch 4, F1 Score: 0.35541747556561365\n",
            "Fold 3, Epoch 5, F1 Score: 0.3737132545185082\n",
            "Fold 3, Epoch 6, F1 Score: 0.38183542169558643\n",
            "Fold 3, Epoch 7, F1 Score: 0.40578493296709617\n",
            "Fold 3, Epoch 8, F1 Score: 0.45164862060933947\n",
            "Fold 3, Epoch 9, F1 Score: 0.4598393326660031\n",
            "Fold 3, Epoch 10, F1 Score: 0.4744955030789841\n",
            "True\n",
            "Fold 4, Epoch 1, F1 Score: 0.23359027766115456\n",
            "Fold 4, Epoch 2, F1 Score: 0.29002501017615784\n",
            "Fold 4, Epoch 3, F1 Score: 0.3123882504807493\n",
            "Fold 4, Epoch 4, F1 Score: 0.3166519749541682\n",
            "Fold 4, Epoch 5, F1 Score: 0.34867267362054194\n",
            "Fold 4, Epoch 6, F1 Score: 0.41149106091868165\n",
            "Fold 4, Epoch 7, F1 Score: 0.4321199055327794\n",
            "Fold 4, Epoch 8, F1 Score: 0.4649237624029848\n",
            "Fold 4, Epoch 9, F1 Score: 0.48848734955330225\n",
            "Fold 4, Epoch 10, F1 Score: 0.4956597782950922\n",
            "True\n",
            "Fold 5, Epoch 1, F1 Score: 0.23437214549934912\n",
            "Fold 5, Epoch 2, F1 Score: 0.27659745072525116\n",
            "Fold 5, Epoch 3, F1 Score: 0.30818440594275803\n",
            "Fold 5, Epoch 4, F1 Score: 0.342385862288126\n",
            "Fold 5, Epoch 5, F1 Score: 0.3533057214902437\n",
            "Fold 5, Epoch 6, F1 Score: 0.40638552925964344\n",
            "Fold 5, Epoch 7, F1 Score: 0.44592622254180414\n",
            "Fold 5, Epoch 8, F1 Score: 0.4612007325669136\n",
            "Fold 5, Epoch 9, F1 Score: 0.4782220679482272\n",
            "Fold 5, Epoch 10, F1 Score: 0.49513838579596614\n",
            "Training with optimizer: RMSprop, learning rate: 0.0001, batch size: 64\n",
            "True\n",
            "Fold 1, Epoch 1, F1 Score: 0.7357777483239084\n",
            "Fold 1, Epoch 2, F1 Score: 0.8120299572212923\n",
            "Fold 1, Epoch 3, F1 Score: 0.7909148143962601\n",
            "Fold 1, Epoch 4, F1 Score: 0.7946568580252786\n",
            "Fold 1, Epoch 5, F1 Score: 0.7864859483214292\n",
            "Fold 1, Epoch 6, F1 Score: 0.7898503246805757\n",
            "Fold 1, Epoch 7, F1 Score: 0.8091968009782056\n",
            "Fold 1, Epoch 8, F1 Score: 0.7989525092611195\n",
            "Fold 1, Epoch 9, F1 Score: 0.7656220291390493\n",
            "Fold 1, Epoch 10, F1 Score: 0.7809029994738593\n",
            "True\n",
            "Fold 2, Epoch 1, F1 Score: 0.756259698621259\n",
            "Fold 2, Epoch 2, F1 Score: 0.7641637737633555\n",
            "Fold 2, Epoch 3, F1 Score: 0.7597206479482504\n",
            "Fold 2, Epoch 4, F1 Score: 0.7659580295193301\n",
            "Fold 2, Epoch 5, F1 Score: 0.7597460001296895\n",
            "Fold 2, Epoch 6, F1 Score: 0.7711632542167651\n",
            "Fold 2, Epoch 7, F1 Score: 0.74791384721162\n",
            "Fold 2, Epoch 8, F1 Score: 0.7585272334141752\n",
            "Fold 2, Epoch 9, F1 Score: 0.7722077413462776\n",
            "Fold 2, Epoch 10, F1 Score: 0.7901915644211558\n",
            "True\n",
            "Fold 3, Epoch 1, F1 Score: 0.7323270413251203\n",
            "Fold 3, Epoch 2, F1 Score: 0.7564781445149998\n",
            "Fold 3, Epoch 3, F1 Score: 0.7446915474864855\n",
            "Fold 3, Epoch 4, F1 Score: 0.7604960404374229\n",
            "Fold 3, Epoch 5, F1 Score: 0.7440109834040215\n",
            "Fold 3, Epoch 6, F1 Score: 0.7335461998162778\n",
            "Fold 3, Epoch 7, F1 Score: 0.7452155815859903\n",
            "Fold 3, Epoch 8, F1 Score: 0.7525397757403601\n",
            "Fold 3, Epoch 9, F1 Score: 0.7732716029193791\n",
            "Fold 3, Epoch 10, F1 Score: 0.7515838505334385\n",
            "True\n",
            "Fold 4, Epoch 1, F1 Score: 0.789653682539996\n",
            "Fold 4, Epoch 2, F1 Score: 0.7684847601132626\n",
            "Fold 4, Epoch 3, F1 Score: 0.7797480855069518\n",
            "Fold 4, Epoch 4, F1 Score: 0.7831263989943595\n",
            "Fold 4, Epoch 5, F1 Score: 0.7902276158887087\n",
            "Fold 4, Epoch 6, F1 Score: 0.7716967667133229\n",
            "Fold 4, Epoch 7, F1 Score: 0.7890273541472338\n",
            "Fold 4, Epoch 8, F1 Score: 0.7714517751755555\n",
            "Fold 4, Epoch 9, F1 Score: 0.790254453748091\n",
            "Fold 4, Epoch 10, F1 Score: 0.7905741164753927\n",
            "True\n",
            "Fold 5, Epoch 1, F1 Score: 0.7335187503099952\n",
            "Fold 5, Epoch 2, F1 Score: 0.7674817212671786\n",
            "Fold 5, Epoch 3, F1 Score: 0.7391442572357668\n",
            "Fold 5, Epoch 4, F1 Score: 0.7635015884106645\n",
            "Fold 5, Epoch 5, F1 Score: 0.7631944279133341\n",
            "Fold 5, Epoch 6, F1 Score: 0.7523207268220449\n",
            "Fold 5, Epoch 7, F1 Score: 0.7470506491201979\n",
            "Fold 5, Epoch 8, F1 Score: 0.7664562737517052\n",
            "Fold 5, Epoch 9, F1 Score: 0.745620439028562\n",
            "Fold 5, Epoch 10, F1 Score: 0.7581522210221782\n",
            "Training with optimizer: Adam, learning rate: 0.0001, batch size: 128\n",
            "True\n",
            "Fold 1, Epoch 1, F1 Score: 0.6704377742721567\n",
            "Fold 1, Epoch 2, F1 Score: 0.7559797808517144\n",
            "Fold 1, Epoch 3, F1 Score: 0.7430922554627332\n",
            "Fold 1, Epoch 4, F1 Score: 0.7787008100777729\n",
            "Fold 1, Epoch 5, F1 Score: 0.76734223340259\n",
            "Fold 1, Epoch 6, F1 Score: 0.7614435702438667\n",
            "Fold 1, Epoch 7, F1 Score: 0.759660715940074\n",
            "Fold 1, Epoch 8, F1 Score: 0.7691674774489128\n",
            "Fold 1, Epoch 9, F1 Score: 0.7507102948553381\n",
            "Fold 1, Epoch 10, F1 Score: 0.7775522248038498\n",
            "True\n",
            "Fold 2, Epoch 1, F1 Score: 0.6309863870579108\n",
            "Fold 2, Epoch 2, F1 Score: 0.7364560376369947\n",
            "Fold 2, Epoch 3, F1 Score: 0.7365358891957291\n",
            "Fold 2, Epoch 4, F1 Score: 0.7560806408437483\n",
            "Fold 2, Epoch 5, F1 Score: 0.7480167764733819\n",
            "Fold 2, Epoch 6, F1 Score: 0.7476470844417568\n",
            "Fold 2, Epoch 7, F1 Score: 0.7461146243019332\n",
            "Fold 2, Epoch 8, F1 Score: 0.7424232569956842\n",
            "Fold 2, Epoch 9, F1 Score: 0.7538281968595836\n",
            "Fold 2, Epoch 10, F1 Score: 0.763286072501821\n",
            "True\n",
            "Fold 3, Epoch 1, F1 Score: 0.6408452436380014\n",
            "Fold 3, Epoch 2, F1 Score: 0.7091618046687759\n",
            "Fold 3, Epoch 3, F1 Score: 0.7427233423824845\n",
            "Fold 3, Epoch 4, F1 Score: 0.7404925398089505\n",
            "Fold 3, Epoch 5, F1 Score: 0.740698405432187\n",
            "Fold 3, Epoch 6, F1 Score: 0.7382262881548239\n",
            "Fold 3, Epoch 7, F1 Score: 0.7579087742976509\n",
            "Fold 3, Epoch 8, F1 Score: 0.7377184737194096\n",
            "Fold 3, Epoch 9, F1 Score: 0.7423309011132404\n",
            "Fold 3, Epoch 10, F1 Score: 0.7466510383720877\n",
            "True\n",
            "Fold 4, Epoch 1, F1 Score: 0.6338772296503274\n",
            "Fold 4, Epoch 2, F1 Score: 0.7469166364587502\n",
            "Fold 4, Epoch 3, F1 Score: 0.7684996147938739\n",
            "Fold 4, Epoch 4, F1 Score: 0.7731831318840535\n",
            "Fold 4, Epoch 5, F1 Score: 0.7750401278176144\n",
            "Fold 4, Epoch 6, F1 Score: 0.7524011732031313\n",
            "Fold 4, Epoch 7, F1 Score: 0.7573832429090355\n",
            "Fold 4, Epoch 8, F1 Score: 0.7636240887311857\n",
            "Fold 4, Epoch 9, F1 Score: 0.7719458255342492\n",
            "Fold 4, Epoch 10, F1 Score: 0.7718020024585015\n",
            "True\n",
            "Fold 5, Epoch 1, F1 Score: 0.6640342358778867\n",
            "Fold 5, Epoch 2, F1 Score: 0.7449411449775499\n",
            "Fold 5, Epoch 3, F1 Score: 0.7303737515994461\n",
            "Fold 5, Epoch 4, F1 Score: 0.733757328787048\n",
            "Fold 5, Epoch 5, F1 Score: 0.7327966853839664\n",
            "Fold 5, Epoch 6, F1 Score: 0.7329586731533354\n",
            "Fold 5, Epoch 7, F1 Score: 0.7382412528316822\n",
            "Fold 5, Epoch 8, F1 Score: 0.7324550435414968\n",
            "Fold 5, Epoch 9, F1 Score: 0.7377102143708288\n",
            "Fold 5, Epoch 10, F1 Score: 0.7445665447327571\n",
            "Training with optimizer: SGD, learning rate: 0.0001, batch size: 128\n",
            "True\n",
            "Fold 1, Epoch 1, F1 Score: 0.17403809599939643\n",
            "Fold 1, Epoch 2, F1 Score: 0.2333890033628708\n",
            "Fold 1, Epoch 3, F1 Score: 0.2668764131014329\n",
            "Fold 1, Epoch 4, F1 Score: 0.2792475240050541\n",
            "Fold 1, Epoch 5, F1 Score: 0.3017159285947287\n",
            "Fold 1, Epoch 6, F1 Score: 0.3092060052704623\n",
            "Fold 1, Epoch 7, F1 Score: 0.3180490184978515\n",
            "Fold 1, Epoch 8, F1 Score: 0.3250527901080387\n",
            "Fold 1, Epoch 9, F1 Score: 0.33548590839786696\n",
            "Fold 1, Epoch 10, F1 Score: 0.349555233104985\n",
            "True\n",
            "Fold 2, Epoch 1, F1 Score: 0.16280850597258825\n",
            "Fold 2, Epoch 2, F1 Score: 0.22645949336502869\n",
            "Fold 2, Epoch 3, F1 Score: 0.26649801819261537\n",
            "Fold 2, Epoch 4, F1 Score: 0.2888653361157217\n",
            "Fold 2, Epoch 5, F1 Score: 0.2980676987258161\n",
            "Fold 2, Epoch 6, F1 Score: 0.3097474379892318\n",
            "Fold 2, Epoch 7, F1 Score: 0.31450710071605664\n",
            "Fold 2, Epoch 8, F1 Score: 0.3267679341925658\n",
            "Fold 2, Epoch 9, F1 Score: 0.35106182774002076\n",
            "Fold 2, Epoch 10, F1 Score: 0.36693903575597836\n",
            "True\n",
            "Fold 3, Epoch 1, F1 Score: 0.1507867501984171\n",
            "Fold 3, Epoch 2, F1 Score: 0.22832313165857668\n",
            "Fold 3, Epoch 3, F1 Score: 0.2660028455191631\n",
            "Fold 3, Epoch 4, F1 Score: 0.303853399663279\n",
            "Fold 3, Epoch 5, F1 Score: 0.31666465817442985\n",
            "Fold 3, Epoch 6, F1 Score: 0.332284926350129\n",
            "Fold 3, Epoch 7, F1 Score: 0.3459786624219754\n",
            "Fold 3, Epoch 8, F1 Score: 0.3648747171185737\n",
            "Fold 3, Epoch 9, F1 Score: 0.3700898706471885\n",
            "Fold 3, Epoch 10, F1 Score: 0.4021838285051021\n",
            "True\n",
            "Fold 4, Epoch 1, F1 Score: 0.16878797370502888\n",
            "Fold 4, Epoch 2, F1 Score: 0.2632812779941715\n",
            "Fold 4, Epoch 3, F1 Score: 0.2865021052791487\n",
            "Fold 4, Epoch 4, F1 Score: 0.3089025529950771\n",
            "Fold 4, Epoch 5, F1 Score: 0.3303237145978395\n",
            "Fold 4, Epoch 6, F1 Score: 0.3354324217870605\n",
            "Fold 4, Epoch 7, F1 Score: 0.3511630096333957\n",
            "Fold 4, Epoch 8, F1 Score: 0.36596475487233765\n",
            "Fold 4, Epoch 9, F1 Score: 0.38414499872155666\n",
            "Fold 4, Epoch 10, F1 Score: 0.38703466789923907\n",
            "True\n",
            "Fold 5, Epoch 1, F1 Score: 0.15226783446591394\n",
            "Fold 5, Epoch 2, F1 Score: 0.24269694199519676\n",
            "Fold 5, Epoch 3, F1 Score: 0.27173778962351886\n",
            "Fold 5, Epoch 4, F1 Score: 0.29776176033724516\n",
            "Fold 5, Epoch 5, F1 Score: 0.3054130179530245\n",
            "Fold 5, Epoch 6, F1 Score: 0.3234601624003721\n",
            "Fold 5, Epoch 7, F1 Score: 0.3432491765715915\n",
            "Fold 5, Epoch 8, F1 Score: 0.3467552045268382\n",
            "Fold 5, Epoch 9, F1 Score: 0.3647133848925734\n",
            "Fold 5, Epoch 10, F1 Score: 0.38418998716130587\n",
            "Training with optimizer: RMSprop, learning rate: 0.0001, batch size: 128\n",
            "True\n",
            "Fold 1, Epoch 1, F1 Score: 0.7537146969269068\n",
            "Fold 1, Epoch 2, F1 Score: 0.7866397182443996\n",
            "Fold 1, Epoch 3, F1 Score: 0.7890723227497175\n",
            "Fold 1, Epoch 4, F1 Score: 0.7934343808996193\n",
            "Fold 1, Epoch 5, F1 Score: 0.8022049630366471\n",
            "Fold 1, Epoch 6, F1 Score: 0.7973800980656712\n",
            "Fold 1, Epoch 7, F1 Score: 0.7888979573494287\n",
            "Fold 1, Epoch 8, F1 Score: 0.8011236289086706\n",
            "Fold 1, Epoch 9, F1 Score: 0.7827956405468126\n",
            "Fold 1, Epoch 10, F1 Score: 0.8005558949054158\n",
            "True\n",
            "Fold 2, Epoch 1, F1 Score: 0.732563682661744\n",
            "Fold 2, Epoch 2, F1 Score: 0.7729402976914685\n",
            "Fold 2, Epoch 3, F1 Score: 0.7847071647251216\n",
            "Fold 2, Epoch 4, F1 Score: 0.7727764067531532\n",
            "Fold 2, Epoch 5, F1 Score: 0.7672466947796611\n",
            "Fold 2, Epoch 6, F1 Score: 0.7668047237597396\n",
            "Fold 2, Epoch 7, F1 Score: 0.7784802433019057\n",
            "Fold 2, Epoch 8, F1 Score: 0.7549158831385983\n",
            "Fold 2, Epoch 9, F1 Score: 0.7767246930022907\n",
            "Fold 2, Epoch 10, F1 Score: 0.7771134121064639\n",
            "True\n",
            "Fold 3, Epoch 1, F1 Score: 0.7066651143627417\n",
            "Fold 3, Epoch 2, F1 Score: 0.7698888809018022\n",
            "Fold 3, Epoch 3, F1 Score: 0.7617263013264205\n",
            "Fold 3, Epoch 4, F1 Score: 0.7673322068997157\n",
            "Fold 3, Epoch 5, F1 Score: 0.7577842709157507\n",
            "Fold 3, Epoch 6, F1 Score: 0.7513279161779921\n",
            "Fold 3, Epoch 7, F1 Score: 0.767296682148218\n",
            "Fold 3, Epoch 8, F1 Score: 0.767894487797383\n",
            "Fold 3, Epoch 9, F1 Score: 0.7707915275946055\n",
            "Fold 3, Epoch 10, F1 Score: 0.748573914333995\n",
            "True\n",
            "Fold 4, Epoch 1, F1 Score: 0.7106291333263739\n",
            "Fold 4, Epoch 2, F1 Score: 0.7628971749708895\n",
            "Fold 4, Epoch 3, F1 Score: 0.7531303748951713\n",
            "Fold 4, Epoch 4, F1 Score: 0.7739862530675893\n",
            "Fold 4, Epoch 5, F1 Score: 0.7688741629753642\n",
            "Fold 4, Epoch 6, F1 Score: 0.7826596185420146\n",
            "Fold 4, Epoch 7, F1 Score: 0.7746345360251999\n",
            "Fold 4, Epoch 8, F1 Score: 0.7862983504802906\n",
            "Fold 4, Epoch 9, F1 Score: 0.7573091008433979\n",
            "Fold 4, Epoch 10, F1 Score: 0.7644206921055682\n",
            "True\n",
            "Fold 5, Epoch 1, F1 Score: 0.7349219886140127\n",
            "Fold 5, Epoch 2, F1 Score: 0.75860529390723\n",
            "Fold 5, Epoch 3, F1 Score: 0.7453492672248608\n",
            "Fold 5, Epoch 4, F1 Score: 0.7720920923700918\n",
            "Fold 5, Epoch 5, F1 Score: 0.7658260612507868\n",
            "Fold 5, Epoch 6, F1 Score: 0.7399430291919383\n",
            "Fold 5, Epoch 7, F1 Score: 0.7447920618010907\n",
            "Fold 5, Epoch 8, F1 Score: 0.7548222894618745\n",
            "Fold 5, Epoch 9, F1 Score: 0.7495827730831947\n",
            "Fold 5, Epoch 10, F1 Score: 0.7496312176408515\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\"\"\"# ResNet18\"\"\"\n",
        "\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "# An empty list for storing the results\n",
        "results = []\n",
        "f1_vals = [0] * k_folds\n",
        "results.append({'Model': 'ResNet18'})\n",
        "\n",
        "# Initialize lists to store training and validation losses and accuracies\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "epochs = 10\n",
        "num_epochs = epochs\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for batch_size in batch_sizes:\n",
        "      for optimizer_name in optimizers:\n",
        "        print(f\"Training with optimizer: {optimizer_name}, learning rate: {lr}, batch size: {batch_size}\")\n",
        "        for fold, (train_idx, val_idx) in enumerate(skf.split(dataset.imgs, dataset.targets)):\n",
        "            train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
        "            val_sampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
        "\n",
        "            train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "            val_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=val_sampler)\n",
        "\n",
        "            best_f1 = 0\n",
        "            # Define the device (GPU if available, otherwise CPU)\n",
        "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "            print(torch.cuda.is_available())\n",
        "\n",
        "            # Define the neural network\n",
        "            model = resnet18(weights='ResNet18_Weights.DEFAULT')\n",
        "            num_ftrs = model.fc.in_features\n",
        "            model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "            model = model.to(device) # Move the model to GPU\n",
        "\n",
        "            # Define loss function\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            # Define optimizer\n",
        "            if optimizer_name == 'Adam':\n",
        "                optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "            elif optimizer_name == 'SGD':\n",
        "                optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "            elif optimizer_name == 'RMSprop':\n",
        "                optimizer = optim.RMSprop(model.parameters(), lr=lr)\n",
        "\n",
        "            # Train and evaluate\n",
        "            for epoch in range(num_epochs):\n",
        "                # Training loop\n",
        "                model.train()\n",
        "                running_loss = 0.0\n",
        "                correct = 0\n",
        "                total = 0\n",
        "                for inputs, labels in train_loader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device) # Move inputs and labels to GPU\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    running_loss += loss.item()\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (preds == labels).sum().item()\n",
        "                epoch_train_loss = running_loss / len(train_loader)\n",
        "                epoch_train_accuracy = correct / total\n",
        "                train_losses.append(epoch_train_loss)\n",
        "                train_accuracies.append(epoch_train_accuracy)\n",
        "\n",
        "                # Validation loop\n",
        "                model.eval()\n",
        "                all_preds = []\n",
        "                all_labels = []\n",
        "                running_loss = 0.0\n",
        "                correct = 0\n",
        "                total = 0\n",
        "                with torch.no_grad():\n",
        "                  for inputs, labels in val_loader:\n",
        "                      inputs, labels = inputs.to(device), labels.to(device) # Move inputs and labels to GPU\n",
        "                      outputs = model(inputs)\n",
        "                      loss = criterion(outputs, labels)\n",
        "                      running_loss += loss.item()\n",
        "                      _, preds = torch.max(outputs, 1)\n",
        "                      total += labels.size(0)\n",
        "                      correct += (preds == labels).sum().item()\n",
        "                      all_preds.extend(preds.cpu().numpy())\n",
        "                      all_labels.extend(labels.cpu().numpy())\n",
        "                epoch_val_loss = running_loss / len(val_loader)\n",
        "                epoch_val_accuracy = correct / total\n",
        "                val_losses.append(epoch_val_loss)\n",
        "                val_accuracies.append(epoch_val_accuracy)\n",
        "\n",
        "                # Calculate F1 score\n",
        "                f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "                print(f\"Fold {fold+1}, Epoch {epoch+1}, F1 Score: {f1}\")\n",
        "\n",
        "                # Update best F1 score and model\n",
        "                if f1 > best_f1:\n",
        "                  best_f1 = f1\n",
        "\n",
        "            f1_vals[fold] = best_f1\n",
        "            results.append({\n",
        "                    'Optimizer': optimizer_name,\n",
        "                    'batch_size': batch_size,\n",
        "                    'learning_rate': lr,\n",
        "                    'Fold': fold+1,\n",
        "                    'F1 Score': best_f1\n",
        "              })\n",
        "        results.append({\n",
        "                  'min f1': min(f1_vals),\n",
        "                  'max f1': max(f1_vals),\n",
        "                  'average f1': sum(f1_vals)/len(f1_vals)\n",
        "                  })\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- Save the results in a excel file ---------------------\n",
        "# Save the results as a DataFrame to be saved in an Excel file\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "# Load an existing Excel file\n",
        "if os.path.isfile(results_directory):\n",
        "  existing_file = pd.read_excel(results_directory)\n",
        "  # Append the new DataFrame to the existing file\n",
        "  df = pd.concat([existing_file, df])\n",
        "\n",
        "# Write the DataFrame to the excel file in the directory\n",
        "df.to_excel(results_directory, index=False)\n",
        "# -------------- End of Save the results in a excel file ----------------\n",
        "\n",
        "# -------------------- Plot the error/epoch plot ------------------------\n",
        "\n",
        "# Define the filename for the Excel file\n",
        "excel_filename = Plot_directory\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(os.path.dirname(excel_filename), exist_ok=True)\n",
        "\n",
        "# Check if the Excel file exists\n",
        "if os.path.exists(excel_filename):\n",
        "    # Load existing Excel file\n",
        "    wb = load_workbook(excel_filename)\n",
        "    ws = wb.active\n",
        "else:\n",
        "    # Create a new Excel workbook\n",
        "    wb = Workbook()\n",
        "    ws = wb.active"
      ],
      "metadata": {
        "id": "KramHB1jlsTM"
      },
      "id": "KramHB1jlsTM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet50"
      ],
      "metadata": {
        "id": "6PGzhfW6joRO"
      },
      "id": "6PGzhfW6joRO"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"#ResNet50\"\"\"\n",
        "\n",
        "from torchvision.models import resnet50\n",
        "\n",
        "# An empty list for storing the results\n",
        "results = []\n",
        "f1_vals = [0] * k_folds\n",
        "results.append({'Model': 'ResNet50'})\n",
        "\n",
        "# Initialize lists to store training and validation losses and accuracies\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "epochs = 10\n",
        "# Define hyperparameters to search over\n",
        "learning_rates = [0.0001]\n",
        "batch_sizes = [32]\n",
        "optimizers = ['Adam', 'SGD', 'RMSprop']\n",
        "num_epochs = epochs\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for batch_size in batch_sizes:\n",
        "      for optimizer_name in optimizers:\n",
        "        print(f\"Training with optimizer: {optimizer_name}, learning rate: {lr}, batch size: {batch_size}\")\n",
        "        for fold, (train_idx, val_idx) in enumerate(skf.split(dataset.imgs, dataset.targets)):\n",
        "            train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
        "            val_sampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
        "\n",
        "            train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "            val_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=val_sampler)\n",
        "\n",
        "            best_f1 = 0\n",
        "            # Define the device (GPU if available, otherwise CPU)\n",
        "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "            # Define the neural network\n",
        "            model = resnet50(weights='ResNet50_Weights.DEFAULT')\n",
        "            num_ftrs = model.fc.in_features\n",
        "            model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "            model = model.to(device) # Move the model to GPU\n",
        "\n",
        "            # Define loss function\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            # Define optimizer\n",
        "            if optimizer_name == 'Adam':\n",
        "                optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "            elif optimizer_name == 'SGD':\n",
        "                optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "            elif optimizer_name == 'RMSprop':\n",
        "                optimizer = optim.RMSprop(model.parameters(), lr=lr)\n",
        "\n",
        "            # Train and evaluate\n",
        "            for epoch in range(num_epochs):\n",
        "                # Training loop\n",
        "                model.train()\n",
        "                running_loss = 0.0\n",
        "                correct = 0\n",
        "                total = 0\n",
        "                for inputs, labels in train_loader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device) # Move inputs and labels to GPU\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    running_loss += loss.item()\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (preds == labels).sum().item()\n",
        "                epoch_train_loss = running_loss / len(train_loader)\n",
        "                epoch_train_accuracy = correct / total\n",
        "                train_losses.append(epoch_train_loss)\n",
        "                train_accuracies.append(epoch_train_accuracy)\n",
        "\n",
        "                # Validation loop\n",
        "                model.eval()\n",
        "                all_preds = []\n",
        "                all_labels = []\n",
        "                running_loss = 0.0\n",
        "                correct = 0\n",
        "                total = 0\n",
        "                with torch.no_grad():\n",
        "                  for inputs, labels in val_loader:\n",
        "                      inputs, labels = inputs.to(device), labels.to(device) # Move inputs and labels to GPU\n",
        "                      outputs = model(inputs)\n",
        "                      loss = criterion(outputs, labels)\n",
        "                      running_loss += loss.item()\n",
        "                      _, preds = torch.max(outputs, 1)\n",
        "                      total += labels.size(0)\n",
        "                      correct += (preds == labels).sum().item()\n",
        "                      all_preds.extend(preds.cpu().numpy())\n",
        "                      all_labels.extend(labels.cpu().numpy())\n",
        "                epoch_val_loss = running_loss / len(val_loader)\n",
        "                epoch_val_accuracy = correct / total\n",
        "                val_losses.append(epoch_val_loss)\n",
        "                val_accuracies.append(epoch_val_accuracy)\n",
        "\n",
        "                # Calculate F1 score\n",
        "                f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "                print(f\"Fold {fold+1}, Epoch {epoch+1}, F1 Score: {f1}\")\n",
        "\n",
        "                # Update best F1 score and model\n",
        "                if f1 > best_f1:\n",
        "                  best_f1 = f1\n",
        "\n",
        "            f1_vals[fold] = best_f1\n",
        "            results.append({\n",
        "                    'Optimizer': optimizer_name,\n",
        "                    'batch_size': batch_size,\n",
        "                    'learning_rate': lr,\n",
        "                    'Fold': fold+1,\n",
        "                    'F1 Score': best_f1\n",
        "              })\n",
        "        results.append({\n",
        "                  'min f1': min(f1_vals),\n",
        "                  'max f1': max(f1_vals),\n",
        "                  'average f1': sum(f1_vals)/len(f1_vals)\n",
        "                  })"
      ],
      "metadata": {
        "id": "XeMarHOzQSKP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c1aa125-1af1-4e73-b7cd-e30baf5a9a90"
      },
      "id": "XeMarHOzQSKP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with optimizer: Adam, learning rate: 0.0001, batch size: 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100%|| 97.8M/97.8M [00:00<00:00, 172MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1, Epoch 1, F1 Score: 0.5690166973267317\n",
            "Fold 1, Epoch 2, F1 Score: 0.7611061146603341\n",
            "Fold 1, Epoch 3, F1 Score: 0.7805996053864265\n",
            "Fold 1, Epoch 4, F1 Score: 0.7930787792076676\n",
            "Fold 1, Epoch 5, F1 Score: 0.8178857888308451\n",
            "Fold 1, Epoch 6, F1 Score: 0.8099341231472881\n",
            "Fold 1, Epoch 7, F1 Score: 0.8094702416521652\n",
            "Fold 1, Epoch 8, F1 Score: 0.8095437629483605\n",
            "Fold 1, Epoch 9, F1 Score: 0.8116510494370592\n",
            "Fold 1, Epoch 10, F1 Score: 0.8313789312159102\n",
            "Fold 2, Epoch 1, F1 Score: 0.5640797767739741\n",
            "Fold 2, Epoch 2, F1 Score: 0.7432720669094849\n",
            "Fold 2, Epoch 3, F1 Score: 0.7709733944769952\n",
            "Fold 2, Epoch 4, F1 Score: 0.7731964138501396\n",
            "Fold 2, Epoch 5, F1 Score: 0.775479575343636\n",
            "Fold 2, Epoch 6, F1 Score: 0.7894467927457135\n",
            "Fold 2, Epoch 7, F1 Score: 0.7955602100610318\n",
            "Fold 2, Epoch 8, F1 Score: 0.7832828511879283\n",
            "Fold 2, Epoch 9, F1 Score: 0.7964430553988725\n",
            "Fold 2, Epoch 10, F1 Score: 0.8034643998069059\n",
            "Fold 3, Epoch 1, F1 Score: 0.5386825841736553\n",
            "Fold 3, Epoch 2, F1 Score: 0.7507706456293882\n",
            "Fold 3, Epoch 3, F1 Score: 0.7303847335375191\n",
            "Fold 3, Epoch 4, F1 Score: 0.7482835708495074\n",
            "Fold 3, Epoch 5, F1 Score: 0.7417130481070421\n",
            "Fold 3, Epoch 6, F1 Score: 0.7571253076684014\n",
            "Fold 3, Epoch 7, F1 Score: 0.755199194517875\n",
            "Fold 3, Epoch 8, F1 Score: 0.7774318199932556\n",
            "Fold 3, Epoch 9, F1 Score: 0.7678582010762499\n",
            "Fold 3, Epoch 10, F1 Score: 0.7449455417050843\n",
            "Fold 4, Epoch 1, F1 Score: 0.5890914291047367\n",
            "Fold 4, Epoch 2, F1 Score: 0.7673070570090877\n",
            "Fold 4, Epoch 3, F1 Score: 0.7861220059462664\n",
            "Fold 4, Epoch 4, F1 Score: 0.7829879115055229\n",
            "Fold 4, Epoch 5, F1 Score: 0.7726432829890065\n",
            "Fold 4, Epoch 6, F1 Score: 0.778926414226418\n",
            "Fold 4, Epoch 7, F1 Score: 0.7728020415694177\n",
            "Fold 4, Epoch 8, F1 Score: 0.7910147050184011\n",
            "Fold 4, Epoch 9, F1 Score: 0.7866219133137187\n",
            "Fold 4, Epoch 10, F1 Score: 0.8048763475020081\n",
            "Fold 5, Epoch 1, F1 Score: 0.5442755402024825\n",
            "Fold 5, Epoch 2, F1 Score: 0.7174533306296479\n",
            "Fold 5, Epoch 3, F1 Score: 0.7932244459400835\n",
            "Fold 5, Epoch 4, F1 Score: 0.7627251790815008\n",
            "Fold 5, Epoch 5, F1 Score: 0.7647357820179677\n",
            "Fold 5, Epoch 6, F1 Score: 0.782962418330816\n",
            "Fold 5, Epoch 7, F1 Score: 0.7728961700033207\n",
            "Fold 5, Epoch 8, F1 Score: 0.7806740862527418\n",
            "Fold 5, Epoch 9, F1 Score: 0.7471795524043224\n",
            "Fold 5, Epoch 10, F1 Score: 0.7620239553114941\n",
            "Training with optimizer: SGD, learning rate: 0.0001, batch size: 32\n",
            "Fold 1, Epoch 1, F1 Score: 0.15456187517226505\n",
            "Fold 1, Epoch 2, F1 Score: 0.21060096682190788\n",
            "Fold 1, Epoch 3, F1 Score: 0.24928352015157043\n",
            "Fold 1, Epoch 4, F1 Score: 0.26643675758566726\n",
            "Fold 1, Epoch 5, F1 Score: 0.2964054196653306\n",
            "Fold 1, Epoch 6, F1 Score: 0.31817226936573917\n",
            "Fold 1, Epoch 7, F1 Score: 0.32172800048538835\n",
            "Fold 1, Epoch 8, F1 Score: 0.3287063619964343\n",
            "Fold 1, Epoch 9, F1 Score: 0.3293159174022026\n",
            "Fold 1, Epoch 10, F1 Score: 0.34280675508433517\n",
            "Fold 2, Epoch 1, F1 Score: 0.1550261213537167\n",
            "Fold 2, Epoch 2, F1 Score: 0.20079227009889458\n",
            "Fold 2, Epoch 3, F1 Score: 0.2524305187095253\n",
            "Fold 2, Epoch 4, F1 Score: 0.28139300029256453\n",
            "Fold 2, Epoch 5, F1 Score: 0.2981436932551024\n",
            "Fold 2, Epoch 6, F1 Score: 0.3095696379135962\n",
            "Fold 2, Epoch 7, F1 Score: 0.3155791778296315\n",
            "Fold 2, Epoch 8, F1 Score: 0.32227228680434705\n",
            "Fold 2, Epoch 9, F1 Score: 0.33549372331272953\n",
            "Fold 2, Epoch 10, F1 Score: 0.3592504412101258\n",
            "Fold 3, Epoch 1, F1 Score: 0.16752581973133038\n",
            "Fold 3, Epoch 2, F1 Score: 0.2193203820252311\n",
            "Fold 3, Epoch 3, F1 Score: 0.2620130313834815\n",
            "Fold 3, Epoch 4, F1 Score: 0.28459545861097246\n",
            "Fold 3, Epoch 5, F1 Score: 0.2945036791897118\n",
            "Fold 3, Epoch 6, F1 Score: 0.3130841504069063\n",
            "Fold 3, Epoch 7, F1 Score: 0.321768534535353\n",
            "Fold 3, Epoch 8, F1 Score: 0.331336224852361\n",
            "Fold 3, Epoch 9, F1 Score: 0.339709614755521\n",
            "Fold 3, Epoch 10, F1 Score: 0.34125831430401815\n",
            "Fold 4, Epoch 1, F1 Score: 0.18397036416105308\n",
            "Fold 4, Epoch 2, F1 Score: 0.2244684187491608\n",
            "Fold 4, Epoch 3, F1 Score: 0.25543989175167886\n",
            "Fold 4, Epoch 4, F1 Score: 0.28020864856477584\n",
            "Fold 4, Epoch 5, F1 Score: 0.2912480690720512\n",
            "Fold 4, Epoch 6, F1 Score: 0.30739169610958955\n",
            "Fold 4, Epoch 7, F1 Score: 0.32121464367997593\n",
            "Fold 4, Epoch 8, F1 Score: 0.3128928645075067\n",
            "Fold 4, Epoch 9, F1 Score: 0.33931834463359484\n",
            "Fold 4, Epoch 10, F1 Score: 0.3397412035475058\n",
            "Fold 5, Epoch 1, F1 Score: 0.1551266631754063\n",
            "Fold 5, Epoch 2, F1 Score: 0.19207387554121855\n",
            "Fold 5, Epoch 3, F1 Score: 0.23621113948293615\n",
            "Fold 5, Epoch 4, F1 Score: 0.26889420240639345\n",
            "Fold 5, Epoch 5, F1 Score: 0.28708651573559213\n",
            "Fold 5, Epoch 6, F1 Score: 0.29222482879397776\n",
            "Fold 5, Epoch 7, F1 Score: 0.3202277073136474\n",
            "Fold 5, Epoch 8, F1 Score: 0.3339777786599754\n",
            "Fold 5, Epoch 9, F1 Score: 0.3355735687446771\n",
            "Fold 5, Epoch 10, F1 Score: 0.353660660187943\n",
            "Training with optimizer: RMSprop, learning rate: 0.0001, batch size: 32\n",
            "Fold 1, Epoch 1, F1 Score: 0.7156469100440953\n",
            "Fold 1, Epoch 2, F1 Score: 0.8089600968843254\n",
            "Fold 1, Epoch 3, F1 Score: 0.8166881181559882\n",
            "Fold 1, Epoch 4, F1 Score: 0.739948473725133\n",
            "Fold 1, Epoch 5, F1 Score: 0.7934932999319174\n",
            "Fold 1, Epoch 6, F1 Score: 0.8060637915600224\n",
            "Fold 1, Epoch 7, F1 Score: 0.7816205277652019\n",
            "Fold 1, Epoch 8, F1 Score: 0.8065797676223011\n",
            "Fold 1, Epoch 9, F1 Score: 0.8117273312165931\n",
            "Fold 1, Epoch 10, F1 Score: 0.7968795146949402\n",
            "Fold 2, Epoch 1, F1 Score: 0.6649109860921775\n",
            "Fold 2, Epoch 2, F1 Score: 0.7893750061047963\n",
            "Fold 2, Epoch 3, F1 Score: 0.7896568611017237\n",
            "Fold 2, Epoch 4, F1 Score: 0.7258240462483724\n",
            "Fold 2, Epoch 5, F1 Score: 0.788232581856164\n",
            "Fold 2, Epoch 6, F1 Score: 0.7865667724724048\n",
            "Fold 2, Epoch 7, F1 Score: 0.7664140492480663\n",
            "Fold 2, Epoch 8, F1 Score: 0.7753655401039935\n",
            "Fold 2, Epoch 9, F1 Score: 0.8053255278433453\n",
            "Fold 2, Epoch 10, F1 Score: 0.7897280482733912\n",
            "Fold 3, Epoch 1, F1 Score: 0.6474240894688039\n",
            "Fold 3, Epoch 2, F1 Score: 0.7457754044786142\n",
            "Fold 3, Epoch 3, F1 Score: 0.7394881788818358\n",
            "Fold 3, Epoch 4, F1 Score: 0.6617108510699236\n",
            "Fold 3, Epoch 5, F1 Score: 0.7378915293256382\n",
            "Fold 3, Epoch 6, F1 Score: 0.7284330713303695\n",
            "Fold 3, Epoch 7, F1 Score: 0.7438850326835102\n",
            "Fold 3, Epoch 8, F1 Score: 0.7562633681072479\n",
            "Fold 3, Epoch 9, F1 Score: 0.7451806645355034\n",
            "Fold 3, Epoch 10, F1 Score: 0.7708957979623685\n",
            "Fold 4, Epoch 1, F1 Score: 0.6568471863011521\n",
            "Fold 4, Epoch 2, F1 Score: 0.7267479139089005\n",
            "Fold 4, Epoch 3, F1 Score: 0.7848855927406366\n",
            "Fold 4, Epoch 4, F1 Score: 0.7634620351425759\n",
            "Fold 4, Epoch 5, F1 Score: 0.7909508102787216\n",
            "Fold 4, Epoch 6, F1 Score: 0.7518889374947997\n",
            "Fold 4, Epoch 7, F1 Score: 0.690824950131387\n",
            "Fold 4, Epoch 8, F1 Score: 0.7682741512309784\n",
            "Fold 4, Epoch 9, F1 Score: 0.7081247978575117\n",
            "Fold 4, Epoch 10, F1 Score: 0.7401905730051449\n",
            "Fold 5, Epoch 1, F1 Score: 0.6903281118459521\n",
            "Fold 5, Epoch 2, F1 Score: 0.758307768519752\n",
            "Fold 5, Epoch 3, F1 Score: 0.7886953859784954\n",
            "Fold 5, Epoch 4, F1 Score: 0.7870255249560718\n",
            "Fold 5, Epoch 5, F1 Score: 0.7699045998513935\n",
            "Fold 5, Epoch 6, F1 Score: 0.7755375617506659\n",
            "Fold 5, Epoch 7, F1 Score: 0.7446893663390955\n",
            "Fold 5, Epoch 8, F1 Score: 0.753555310496843\n",
            "Fold 5, Epoch 9, F1 Score: 0.7976570897359773\n",
            "Fold 5, Epoch 10, F1 Score: 0.7661642620194704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- Save the results in a excel file ---------------------\n",
        "# Save the results as a DataFrame to be saved in an Excel file\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "# Load an existing Excel file\n",
        "if os.path.isfile(results_directory):\n",
        "  existing_file = pd.read_excel(results_directory)\n",
        "  # Append the new DataFrame to the existing file\n",
        "  df = pd.concat([existing_file, df])\n",
        "\n",
        "# Write the DataFrame to the excel file in the directory\n",
        "df.to_excel(results_directory, index=False)\n",
        "# -------------- End of Save the results in a excel file ----------------\n",
        "\n",
        "# -------------------- Plot the error/epoch plot ------------------------\n",
        "\n",
        "# Define the filename for the Excel file\n",
        "excel_filename = Plot_directory\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(os.path.dirname(excel_filename), exist_ok=True)\n",
        "\n",
        "# Check if the Excel file exists\n",
        "if os.path.exists(excel_filename):\n",
        "    # Load existing Excel file\n",
        "    wb = load_workbook(excel_filename)\n",
        "    ws = wb.active\n",
        "else:\n",
        "    # Create a new Excel workbook\n",
        "    wb = Workbook()\n",
        "    ws = wb.active"
      ],
      "metadata": {
        "id": "3te4SRWzmW_L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2c12af5f-30b3-47ae-84cb-1043215f53c3"
      },
      "id": "3te4SRWzmW_L",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# Append data to the DataFrame (train_losses, val_losses, train_accuracies, val_accuracies are assumed to be lists)\\ndf['Train Loss'] = train_losses\\ndf['Val Loss'] = val_losses\\ndf['Train Accuracy'] = train_accuracies\\ndf['Val Accuracy'] = val_accuracies\\nnum_epochs = train_losses\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EfficientNetB0"
      ],
      "metadata": {
        "id": "CcXMwtxgjtoF"
      },
      "id": "CcXMwtxgjtoF"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"# EfficientNetB0\"\"\"\n",
        "\n",
        "! pip install --upgrade efficientnet-pytorch\n",
        "\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "# An empty list for storing the results\n",
        "results = []\n",
        "f1_vals = [0] * k_folds\n",
        "results.append({'Model': 'EfficientNetB0'})\n",
        "\n",
        "# Initialize lists to store training and validation losses and accuracies\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "num_epochs = epochs\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for batch_size in batch_sizes:\n",
        "      for optimizer_name in optimizers:\n",
        "        print(f\"Training with optimizer: {optimizer_name}, learning rate: {lr}, batch size: {batch_size}\")\n",
        "        for fold, (train_idx, val_idx) in enumerate(skf.split(dataset.imgs, dataset.targets)):\n",
        "            train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
        "            val_sampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
        "\n",
        "            train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "            val_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=val_sampler)\n",
        "\n",
        "            best_f1 = 0\n",
        "            # Define the device (GPU if available, otherwise CPU)\n",
        "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "            # Define the neural network\n",
        "            model = EfficientNet.from_pretrained('efficientnet-b0', num_classes).to(device)  # Move the model to GPU\n",
        "\n",
        "            # Define loss function\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            # Define optimizer\n",
        "            if optimizer_name == 'Adam':\n",
        "                optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "            elif optimizer_name == 'SGD':\n",
        "                optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "            elif optimizer_name == 'RMSprop':\n",
        "                optimizer = optim.RMSprop(model.parameters(), lr=lr)\n",
        "\n",
        "            # Train and evaluate\n",
        "            for epoch in range(num_epochs):\n",
        "                # Training loop\n",
        "                model.train()\n",
        "                running_loss = 0.0\n",
        "                correct = 0\n",
        "                total = 0\n",
        "                for inputs, labels in train_loader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device) # Move inputs and labels to GPU\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    running_loss += loss.item()\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (preds == labels).sum().item()\n",
        "                epoch_train_loss = running_loss / len(train_loader)\n",
        "                epoch_train_accuracy = correct / total\n",
        "                train_losses.append(epoch_train_loss)\n",
        "                train_accuracies.append(epoch_train_accuracy)\n",
        "\n",
        "                # Validation loop\n",
        "                model.eval()\n",
        "                all_preds = []\n",
        "                all_labels = []\n",
        "                running_loss = 0.0\n",
        "                correct = 0\n",
        "                total = 0\n",
        "                with torch.no_grad():\n",
        "                  for inputs, labels in val_loader:\n",
        "                      inputs, labels = inputs.to(device), labels.to(device) # Move inputs and labels to GPU\n",
        "                      outputs = model(inputs)\n",
        "                      loss = criterion(outputs, labels)\n",
        "                      running_loss += loss.item()\n",
        "                      _, preds = torch.max(outputs, 1)\n",
        "                      total += labels.size(0)\n",
        "                      correct += (preds == labels).sum().item()\n",
        "                      all_preds.extend(preds.cpu().numpy())\n",
        "                      all_labels.extend(labels.cpu().numpy())\n",
        "                epoch_val_loss = running_loss / len(val_loader)\n",
        "                epoch_val_accuracy = correct / total\n",
        "                val_losses.append(epoch_val_loss)\n",
        "                val_accuracies.append(epoch_val_accuracy)\n",
        "\n",
        "                # Calculate F1 score\n",
        "                f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "                print(f\"Fold {fold+1}, Epoch {epoch+1}, F1 Score: {f1}\")\n",
        "\n",
        "                # Update best F1 score and model\n",
        "                if f1 > best_f1:\n",
        "                  best_f1 = f1\n",
        "\n",
        "            f1_vals[fold] = best_f1\n",
        "            results.append({\n",
        "                    'Optimizer': optimizer_name,\n",
        "                    'batch_size': batch_size,\n",
        "                    'learning_rate': lr,\n",
        "                    'Fold': fold+1,\n",
        "                    'F1 Score': best_f1\n",
        "              })\n",
        "        results.append({\n",
        "                  'min f1': min(f1_vals),\n",
        "                  'max f1': max(f1_vals),\n",
        "                  'average f1': sum(f1_vals)/len(f1_vals)\n",
        "                  })\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f7YDJZ5QQF7X",
        "outputId": "46e2da8d-ce24-4da5-8aa9-1ef8f75e7966"
      },
      "id": "f7YDJZ5QQF7X",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting efficientnet-pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch) (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->efficientnet-pytorch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->efficientnet-pytorch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->efficientnet-pytorch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->efficientnet-pytorch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->efficientnet-pytorch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->efficientnet-pytorch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->efficientnet-pytorch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->efficientnet-pytorch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->efficientnet-pytorch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->efficientnet-pytorch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->efficientnet-pytorch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->efficientnet-pytorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch) (1.3.0)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16429 sha256=b09ff582d4dcf7f3843f9e45dfc9c282b3012a139b92b6e73c9b9cb0dc86cdcc\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105\n",
            "Training with optimizer: Adam, learning rate: 0.001, batch size: 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b0-355c32eb.pth\n",
            "100%|| 20.4M/20.4M [00:00<00:00, 466MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b0\n",
            "Fold 1, Epoch 1, F1 Score: 0.5365134832149322\n",
            "Fold 1, Epoch 2, F1 Score: 0.641612705377988\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-5ad436cf2743>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                     \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ----------------- Save the results in a excel file ---------------------\n",
        "# Save the results as a DataFrame to be saved in an Excel file\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "# Load an existing Excel file\n",
        "if os.path.isfile(results_directory):\n",
        "  existing_file = pd.read_excel(results_directory)\n",
        "  # Append the new DataFrame to the existing file\n",
        "  df = pd.concat([existing_file, df])\n",
        "\n",
        "# Write the DataFrame to the excel file in the directory\n",
        "df.to_excel(results_directory, index=False)\n",
        "# -------------- End of Save the results in a excel file ----------------\n",
        "\n",
        "# -------------------- Plot the error/epoch plot ------------------------\n",
        "\n",
        "# Define the filename for the Excel file\n",
        "excel_filename = Plot_directory\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(os.path.dirname(excel_filename), exist_ok=True)\n",
        "\n",
        "# Check if the Excel file exists\n",
        "if os.path.exists(excel_filename):\n",
        "    # Load existing Excel file\n",
        "    wb = load_workbook(excel_filename)\n",
        "    ws = wb.active\n",
        "else:\n",
        "    # Create a new Excel workbook\n",
        "    wb = Workbook()\n",
        "    ws = wb.active"
      ],
      "metadata": {
        "id": "U18fYRGHoGce"
      },
      "id": "U18fYRGHoGce",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "encoding": "# -*- coding: utf-8 -*-",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e15c5b77190d4d58b20721ba2b560ed5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7493f6137bae478ca3d498a7499c6faa",
              "IPY_MODEL_7cdfb86992574375b12c4f855fa22b47",
              "IPY_MODEL_c6b4bf9cf79f4e8c960038894914e8f6"
            ],
            "layout": "IPY_MODEL_d6f8b7af62934a3dbadae60ce6d4717b"
          }
        },
        "7493f6137bae478ca3d498a7499c6faa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99df0033143f4abf840bf362cd83b220",
            "placeholder": "",
            "style": "IPY_MODEL_5eb2a5628cad4f159587ee8bfea63ecb",
            "value": "config.json:100%"
          }
        },
        "7cdfb86992574375b12c4f855fa22b47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9dadfbdf83a432d8f16b8761b3cd377",
            "max": 502,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0cda12e1b4274fa5881c22c6ae8b599c",
            "value": 502
          }
        },
        "c6b4bf9cf79f4e8c960038894914e8f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32c32871fe94446a9a9ffb77dcc407ef",
            "placeholder": "",
            "style": "IPY_MODEL_3e24f8f2ac79438fbd9b9c84736db73b",
            "value": "502/502[00:00&lt;00:00,13.9kB/s]"
          }
        },
        "d6f8b7af62934a3dbadae60ce6d4717b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99df0033143f4abf840bf362cd83b220": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5eb2a5628cad4f159587ee8bfea63ecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9dadfbdf83a432d8f16b8761b3cd377": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cda12e1b4274fa5881c22c6ae8b599c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "32c32871fe94446a9a9ffb77dcc407ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e24f8f2ac79438fbd9b9c84736db73b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}